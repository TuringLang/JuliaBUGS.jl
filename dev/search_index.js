var documenterSearchIndex = {"docs":
[{"location":"developers/BUGS_notes/#Miscellaneous-Notes-on-BUGS","page":"Notes on BUGS Implementations","title":"Miscellaneous Notes on BUGS","text":"Here are some exert from BUGS Developer Manual and notes on the original BUGS implementations. ","category":"section"},{"location":"developers/BUGS_notes/#Lexing","page":"Notes on BUGS Implementations","title":"Lexing","text":"The BUGS language has the convention that if a name is followed immediately by a round bracket, that is by a \"(\", then the names is a reserved name in the BUGS language and does not represent a variable in the model.\nBy scanning the stream of tokens that constitute a BUGS language model the names of all the variables in the model can be found.","category":"section"},{"location":"developers/BUGS_notes/#Table-of-Names","page":"Notes on BUGS Implementations","title":"Table of Names","text":"The BUGS language compiler expands all the for loops in the model and records the value of the indices of each use of a tensor on the left hand side of each relation.\nThe range of each index, for a tensor, is set at the maximum value observed value of the index and added to the name table. There is one exception to this procedure for finding index bounds: names that are data, that is in the data source, have the ranges of their indices fixed in the data source.\nEach scalar and each component of a tensor used on the right hand side of a relation must occur either on the left hand side of a relation and or in a data source.","category":"section"},{"location":"developers/BUGS_notes/#Data-Transformations","page":"Notes on BUGS Implementations","title":"Data Transformations","text":"If the compiler can prove that a logical assignment can be evaluated to a constant then the assignment is called a data transformation. This occurs if an assignment's right hand side does not depend on any variable quantities. The BUGS language has a general rule that there must only be one assignment statement for each scalar or component of a tensor.  This rule is slightly relaxed for data transformations. The language allows a logical assignment and a stochastic assignment to the same scalar or tensor component if and only if the logical assignment is a data transformation. ","category":"section"},{"location":"developers/BUGS_notes/#Generated-Quantities","page":"Notes on BUGS Implementations","title":"Generated Quantities","text":"Only need to be evaluated after the inference algorithm has finished its task. \n\nGenerally, these are leaf nodes that logical variables\nIn the case of stochastic variables that are leaf nodes, do “forward sampling”, also part of the generated Quantities","category":"section"},{"location":"developers/BUGS_notes/#Computation","page":"Notes on BUGS Implementations","title":"Computation","text":"All the nodes in the graphical model representing logical relations are placed into an\n\narray and sorted by their nesting level with the first array entries only depending on quantities defined by stochastic relations. Traversing this array and evaluating nodes gives up to date values to all logical relations.","category":"section"},{"location":"developers/BUGS_notes/#Types","page":"Notes on BUGS Implementations","title":"Types","text":"The BUGS compiler uses the properties of the distribution on the right-hand side of a stochastic assignment statement to make deductions about the variable on the left-hand side. For example, r ~ dbin(p, n) implies that r is integer-valued, while x ~ dnorm(mu, tau) implies that x is real-valued.Some distributions are real-valued but have support on a restricted range of the reals. For example, p ~ dbeta(a, b) implies that p is real-valued with support on the unit interval, while x ~ dgamma(r, lambda) implies that x is real-valued but with support on the positive real line.There are two multivariate distributions in the BUGS language, the Dirichlet and the Wishart, that have support on a complex subspace of the reals. The Dirichlet has support on the unit simplex, while the Wishart has support on symmetric positive definite matrices.The BUGS compiler tries to infer if logical relations return an integer value by looking at whether their parents are integer-valued and the operators that combine the values of their parents into the return value. For example, in the cure model example above, the logical relation state1[i] <- state[i] + 1 is integer-valued because state[i] is a Bernoulli variable and therefore integer, the literal 1 is integer, and the sum of two integers is an integer.When the BUGS system reads in data from a data source, it can tag whether the number read is an integer or a real and propagate this information to logical relations. Again, using the cure model as an example, the statement t[i] <- x[i] + y[i] is integer-valued because both x and y are data and are given as integers in the data source.One special type of data is constants: that is just numbers with no associated distribution. Constants have many uses in BUGS language models, but one of the most important is as covariates. A model can contain a large number of constants that are used as covariates. Because of the possible large numbers of these covariate-type constants, they are given special treatment by the BUGS compiler. If a name read in from a data source is only used on the right-hand side of logical relations, no nodes in the graphical model are created to hold its values; they are directly incorporated in the objects that represent the right-hand sides of the logical relations.For example, the large Methadone model contains the regression:mu.indexed[i] <- beta[1] * x1[i] + beta[2] * x2[i] + beta[3] * x3[i] + beta[4] * x4[i] + region.effect[region.indexed[i]] + source.effect[region.indexed[i]] * source.indexed[i] + person.effect[person.indexed[i]]where i ranges from 1 to 240776. Not having to create a node in the graphical model to represent x1, x2, x3, x4, region.indexed, source.index, and person.indexed saves a large amount of space.In the BUGS language, the type information is fine-grained: each component of a tensor can have different type information. This is quite distinct from the situation in STAN and can make it much easier to specify a statistical model. One common case is where some components of a tensor have been observed while other components need to be estimated. The STAN documentation suggests workarounds for these situations, but these are somewhat complex.\n\nThe type propagation is interesting and maybe useful. But we don’t necessarily need to implement a type system. A dirty way to get type information is simply do a dry run with some tricks.","category":"section"},{"location":"developers/BUGS_notes/#Work-flow","page":"Notes on BUGS Implementations","title":"Work flow","text":"The statistical model and data are presented to the BUGS system in a series of stages. In the first stage the model text is parsed into a tree and the name table constructed. The data is then loaded and checked against the model. The data can be split over a number of source. Once all the data has been loaded the model is compiled. Compiling builds the graphical model and does a large number of checks on the consistency of the model. Finally initial values can be given or generated for the model.\n\nThe compiler creates a node in the graphical model for each scalar name and each component of a tensor name in the BUGS language model. The compiler checks that only one node is created for each scalar name or component of a tensor name.\n\nReading in a data source causes the compiler to create special nodes called constant nodes to hold the values of the data.\n\nThe compiler processes logical relations before stochastic relations. Any logical relations that only have constant nodes on their right hand side become new constant nodes with the appropriate fixed value. Even if a logical relation can not be reduced to a constant some parts of the relation might be reduced to constants.\n\nAny constant nodes that have an associated stochastic relation become data nodes in the graphical model.","category":"section"},{"location":"developers/BUGS_notes/#Logical-relations-in-the-BUGS-Language","page":"Notes on BUGS Implementations","title":"Logical relations in the BUGS Language","text":"The OpenBUGS software compiles a description of a statistical model in the BUGS language into a graph of objects. Each relation in the statistical model gives rise to a node in the graph of objects. Each distinct type of relation in the statistical model is represented by a node of a distinct class. For stochastic relations there is a fixed set of distributions that can be used in the modelling. For logical relations the situation is more complex. The software can use arbitrary logical expressions build out of a fixed set of basic operators and functions. For each distinct logical expression a new software source code module is written to implement a class to represent that logical expression in the graph of objects. The software module is then compiled using the Components Pascal compiler and the executable code merged into the running OpenBUGS software using the run time loading linker.The BUGS language description of a statistical model is parsed into a list of trees. The sub-trees that represent logical relations in the statistical model are first converted into a stack based representation and then into Component Pascal source code. The source code is generated in module BugsCPWrite and the source code is then compiled in module BugsCPCompiler. Usually the generated source code is not displayed. Checking the Verbose option in the Info menu will cause each each source code module generated by the OpenBUGS software to be displayed in a separate window.One advantage of a stack based representation of an expression is that it is straight forward to use it to derive source code that calculates the derivative of the expression with respect to its arguments. This part of the source code generation is carried out in module BugsCPWrite in procedure WriteEvaluateDiffMethod. Each operator in the stack representation of the logical expression causes a snippet of Component Pascal code to be written. These code snippets are generally very simple with those of binary operators slightly more complex than those of unitary operators. Each binary operators can emit three different code snippets: the general case and two special snippets depending on whether the left or right operands are numerical constants. The only complex code snippet is when an operand that is a logical relation in the statistical model is pushed onto the stack – the > case of nested logical relations. In this case the nested logical relation will have its own code to calculate derivatives and these values can be passed up the nesting level.The OpenBUGS software now uses a backward mode scheme to calculate the value of logical nodes in the statistical model. All the logical nodes in the statistical model are held in a global array and sorted according to their nesting level with unnested nodes at the start of the array. To evaluate all the logical nodes in the statistical model this array is then traversed and each logical node evaluated and the value stored in the node. The same scheme is used to calculate derivatives.The graphs derived from the BUGS language representation of statistical models are generally sparse. The OpenBUGS software uses conditional independence arguments to exploit sparsity in the stochastic parts of the model. There is also a sparsity structure in logical relations.Each logical relation will often depend on just a few stochastic parents and derivatives with respect to other stochastic nodes in the model will be structurally zero. Each logical node has an associated array of stochastic parents for which the derivatives are non zero. Moving up the level of nesting the number of parents can grow. Dealing with this issue leads to the complexity in the code snippet for the operator that pushes a logical node onto the stack. These issues can be seen in the non-linear random effects model called Orange trees in volume II of the OpenBUGS examples. In this model eta[i,] is a function of phi[i,1], phi[i,2] and phi[i,3] where the phi are also logical functions of the stochastic theta[i,].One refinement of the backward mode scheme used to calculate the value of logical nodes is to consider separately any logical nodes in the statistical model which are only used for prediction and do not affect the calculation of the joint probability distribution. These nodes need only be evaluated once per iteration of the inference algorithm. Examples of such nodes are sigma[k] and sigma.C in the Orange trees example. There is no need to evaluate the derivatives of these prediction nodes.The workings of the backward mode scheme are easy to visualize when the inference algorithm updates all the stochastic nodes in the statistical model in one block. Local versions of the backward mode scheme can be used when the inference algorithm works on single nodes or when a small blocks of nodes are updated. Each stochastic node is given its own vector of logical nodes that depend on it either directly or via other logical nodes and this vector is sorted by nesting level. Each updater that works on small blocks of nodes contains a vector of logical nodes which is the union of the vectors of dependent logical nodes for each of its components.The idea of the backward mode scheme for evaluating logical nodes can be used with caching in Metropolis Hastings sampling. First the vector of logical nodes depending on the relevant stochastic node(s) is evaluated and their values cached. The log of the conditional distribution is then calculated. Next a new value of the stochastic node is proposed. The vector of logical nodes is re-evaluated and the log of the > conditional distribution calculated. If the proposed value is rejected then the cache is used to set the vector of logical nodes back to its old values.The OpenBUGS software also calculates what class of function each logical node is in terms of its stochastic parents. If the software can prove for example that a logical node is a linear function of its parents more efficient sampling algorithms can be used. If a linear relation can be proved then the calculation of derivatives can also be optimized in some cases because they will be constant and so only need to be calculated once. Generalized linear models are implemented in a way that allows fast calculation of derivatives. The structure of the algorithm to classify the functional form of logical nodes is very similar to that for derivatives and uses a backward mode scheme\n\nBUGS separates management of logical and stochastic variables, essentially two graphs. Logical variables are stored in an array and values are updated with values in earlier positions of the array.","category":"section"},{"location":"model_macro/#Defining-Probabilistic-Models-with-JuliaBUGS","page":"@model Macro","title":"Defining Probabilistic Models with JuliaBUGS","text":"JuliaBUGS provides the @model macro for defining probabilistic models in a Julia-native way. This guide explains how to create and use models effectively.","category":"section"},{"location":"model_macro/#The-@model-Macro","page":"@model Macro","title":"The @model Macro","text":"The @model macro creates a function that returns a BUGSModel object. Here's the basic syntax:\n\n@model function model_name(\n    (; param1, param2, ...),     # Stochastic parameters (first argument)\n    constant1, constant2, ...     # Constants and covariates\n)\n    # Model definition using ~ for distributions\nend","category":"section"},{"location":"model_macro/#Function-Signature-Rules","page":"@model Macro","title":"Function Signature Rules","text":"First argument: Must be a named tuple pattern for stochastic parameters\nSimple form: (; x, y, z)\nWith type annotation: (; x, y, z)::MyOfType\nRemaining arguments: All constants, covariates, and structural parameters","category":"section"},{"location":"model_macro/#Two-Types-of-Variables","page":"@model Macro","title":"Two Types of Variables","text":"As shown in the above model, we have two main categories of variables:","category":"section"},{"location":"model_macro/#1.-Stochastic-Parameters","page":"@model Macro","title":"1. Stochastic Parameters","text":"Variables that follow probability distributions, defined with the ~ operator:\n\nUnobserved parameters: Variables to be sampled during inference\nObserved data: Known values that the model conditions on","category":"section"},{"location":"model_macro/#2.-Constants-and-Covariates","page":"@model Macro","title":"2. Constants and Covariates","text":"Deterministic inputs that don't have probability distributions:\n\nCovariates/predictors: Input features like x in regression models\nStructural constants: Values that determine model structure (e.g., N for array sizes)\nFixed parameters: Any other non-stochastic inputs","category":"section"},{"location":"model_macro/#Example:-Linear-Regression","page":"@model Macro","title":"Example: Linear Regression","text":"using Julia\nusing JuliaBUGS.BUGSPrimitives\n\n@model function linear_regression(\n    (; y, beta, sigma),    # y is data, beta and sigma are parameters\n    X, N                   # X is the covariate matrix, N is the size\n)\n    for i in 1:N\n        y[i] ~ dnorm(mu[i], sigma)\n        mu[i] = X[i, :] ⋅ beta\n    end\n    beta ~ dnorm(0, 0.001)\n    sigma ~ dgamma(0.001, 0.001)\nend","category":"section"},{"location":"model_macro/#Type-Specifications-with-of","page":"@model Macro","title":"Type Specifications with of","text":"JuliaBUGS provides an of type system for specifying parameter structures and constraints. For a comprehensive guide to the of type system, including advanced features like symbolic dimensions, arithmetic expressions, and dynamic model structures, see the of Design Documentation.\n\nThe of system serves two main purposes:\n\nDocuments the expected structure of parameters\nValidates the model after compilation to ensure type safety","category":"section"},{"location":"model_macro/#Quick-Example","page":"@model Macro","title":"Quick Example","text":"# Define a type for regression parameters\nRegressionParams = @of(\n    y = of(Array, Float64, 100),   # Observed data (100 observations)\n    beta = of(Array, Float64, 3),  # Regression coefficients (3 predictors)\n    sigma = of(Real, 0, nothing)   # Positive standard deviation\n)\n\n# Use in model definition\n@model function regression(\n    (; y, beta, sigma)::RegressionParams,\n    X, N, p\n)\n    # Model body...\nend\n\nWhen you provide an of type annotation, JuliaBUGS automatically validates the compiled model's evaluation environment against your type specification.","category":"section"},{"location":"model_macro/#Creating-and-Using-Models","page":"@model Macro","title":"Creating and Using Models","text":"","category":"section"},{"location":"model_macro/#Basic-Model-Creation","page":"@model Macro","title":"Basic Model Creation","text":"# Create model with no observations (sample from prior)\nmodel = my_model((;), constants...)\n\n# Create a model with some observed values\nmodel = my_model((; y = observed_data), constants...)\n\n# Create model with all parameters specified\nmodel = my_model((; param1 = val1, param2 = val2), constants...)","category":"section"},{"location":"model_macro/#Using-unflatten-for-Initialisation","page":"@model Macro","title":"Using unflatten for Initialisation","text":"The unflatten utility helps create parameter instances with missing values:\n\nusing JuliaBUGS: unflatten\n\n# Create a parameter instance with all missing values\nparams = unflatten(MyParamType, missing)\nmodel = my_model(params, constants...)\n\n# This is useful for models that need initialisation","category":"section"},{"location":"model_macro/#Complete-Example:-Hierarchical-Model","page":"@model Macro","title":"Complete Example: Hierarchical Model","text":"Here's a complete example showing all the concepts together:\n\nusing JuliaBUGS\nusing JuliaBUGS.BUGSPrimitives\n\n# Step 1: Define parameter types\nHierarchicalParams = @of(\n    # Data\n    y = of(Array, Float64, 30),     # 30 observations\n    \n    # Group-level parameters\n    theta = of(Array, Float64, 8),  # 8 groups/schools\n    \n    # Hyperparameters\n    mu = of(Real),\n    tau = of(Real, 0, nothing),\n    sigma = of(Real, 0, nothing)\n)\n\n# Step 2: Define the model\n@model function hierarchical(\n    (; y, theta, mu, tau, sigma)::HierarchicalParams,\n    group\n)\n    # Likelihood\n    for i in 1:30\n        y[i] ~ dnorm(theta[group[i]], sigma)\n    end\n    \n    # Group effects\n    for j in 1:8\n        theta[j] ~ dnorm(mu, tau)\n    end\n    \n    # Hyperpriors\n    mu ~ dnorm(0, 0.001)\n    tau ~ dgamma(0.001, 0.001)\n    sigma ~ dgamma(0.001, 0.001)\nend\n\n# Step 3: Create and use the model\n# Prepare data (example: 8 schools data)\ny_obs = randn(30) .+ 0.5    # 30 student outcomes\ngroup_ids = [1,1,1,1, 2,2,2,2, 3,3,3,3, 4,4,4,4, \n             5,5,5, 6,6,6, 7,7,7, 8,8,8,8,8]  # School assignments\n\n# Create model with observations\nmodel = hierarchical(\n    (; y = y_obs),              # Observe y, sample the rest\n    group_ids                   # Covariate: group assignments\n)","category":"section"},{"location":"model_macro/#Important-Notes-and-Restrictions","page":"@model Macro","title":"Important Notes and Restrictions","text":"Type annotation support: Only of types created with the @of macro are supported for type annotations. Regular Julia types will cause an error.\nNo inline annotations: Parameter destructuring doesn't support inline type annotations like (; x::Float64). Use external type definitions instead.\nValidation timing: Type validation occurs after model compilation, not at function definition time.","category":"section"},{"location":"inference/evaluation_modes/#Evaluation-Modes","page":"Evaluation Modes","title":"Evaluation Modes","text":"JuliaBUGS supports multiple evaluation modes that determine how the log density is computed. The evaluation mode also constrains which AD backends can be used.","category":"section"},{"location":"inference/evaluation_modes/#Available-Modes","page":"Evaluation Modes","title":"Available Modes","text":"Mode Description AD Backends\nUseGraph() Traverses computational graph (default) ReverseDiff, ForwardDiff\nUseGeneratedLogDensityFunction() Compiles a Julia function for log density Mooncake\nUseAutoMarginalization() Graph traversal with discrete variable marginalization ReverseDiff, ForwardDiff","category":"section"},{"location":"inference/evaluation_modes/#UseGraph-(Default)","page":"Evaluation Modes","title":"UseGraph (Default)","text":"The default mode evaluates the log density by traversing the computational graph. Works with ReverseDiff and ForwardDiff.\n\nmodel = compile(model_def, data)\n# UseGraph() is the default, no need to set explicitly","category":"section"},{"location":"inference/evaluation_modes/#UseGeneratedLogDensityFunction","page":"Evaluation Modes","title":"UseGeneratedLogDensityFunction","text":"This mode generates and compiles a Julia function for the log density, which can be faster for some models.\n\nmodel = compile(model_def, data)\nmodel = set_evaluation_mode(model, UseGeneratedLogDensityFunction())\n\nUse with Mooncake for AD:\n\nmodel = BUGSModelWithGradient(model, AutoMooncake(; config=nothing))","category":"section"},{"location":"inference/evaluation_modes/#UseAutoMarginalization","page":"Evaluation Modes","title":"UseAutoMarginalization","text":"For models with discrete latent variables, auto-marginalization enables gradient-based inference by marginalizing out discrete parameters. See Auto-Marginalization for details.\n\nmodel = compile(model_def, data)\nmodel = settrans(model, true)  # requires transformed space\nmodel = set_evaluation_mode(model, UseAutoMarginalization())","category":"section"},{"location":"inference/evaluation_modes/#API","page":"Evaluation Modes","title":"API","text":"","category":"section"},{"location":"inference/evaluation_modes/#JuliaBUGS.Model.set_evaluation_mode","page":"Evaluation Modes","title":"JuliaBUGS.Model.set_evaluation_mode","text":"set_evaluation_mode(model::BUGSModel, mode::EvaluationMode)\n\nSet the evaluation mode for the BUGSModel.\n\nThe evaluation mode determines how the log-density of the model is computed. Possible modes are:\n\nUseGeneratedLogDensityFunction(): Uses a statically generated function for log-density computation. This is often faster but may not be available for all models. The function is generated when switching to this mode. If generation fails, a warning is issued and the mode defaults to UseGraph().\nUseGraph(): Computes the log-density by traversing the model's graph structure. This is always available but might be slower.\n\nArguments\n\nmodel::BUGSModel: The BUGS model instance.\nmode::EvaluationMode: The desired evaluation mode.\n\nReturns\n\nA new BUGSModel instance with the evaluation_mode field updated. If the original model is mutable, it might be modified in place.\n\nExamples\n\n# Assuming `model` is a compiled BUGSModel instance\nmodel_with_graph_eval = set_evaluation_mode(model, UseGraph())\nmodel_with_generated_eval = set_evaluation_mode(model, UseGeneratedLogDensityFunction())\n\n\n\n\n\n","category":"function"},{"location":"inference/parallel/#Parallel-and-Distributed-Sampling","page":"Parallel & Distributed Sampling","title":"Parallel and Distributed Sampling","text":"AbstractMCMC and AdvancedHMC support both parallel and distributed sampling.","category":"section"},{"location":"inference/parallel/#Parallel-Sampling-(Multi-threaded)","page":"Parallel & Distributed Sampling","title":"Parallel Sampling (Multi-threaded)","text":"To perform multi-threaded sampling of multiple chains, start Julia with the -t <n_threads> argument.\n\nn_chains = 4\nsamples_and_stats = AbstractMCMC.sample(\n    model,\n    AdvancedHMC.NUTS(0.65),\n    AbstractMCMC.MCMCThreads(),\n    n_samples,\n    n_chains;\n    chain_type = Chains,\n    n_adapts = n_adapts,\n    init_params = [initial_θ for _ = 1:n_chains],\n    discard_initial = n_adapts,\n)\n\nThe key differences from single-chain sampling:\n\nAbstractMCMC.MCMCThreads(): enables multi-threaded sampling\nn_chains: number of chains to sample in parallel\ninit_params: vector of initial parameters (one per chain)","category":"section"},{"location":"inference/parallel/#Distributed-Sampling-(Multi-process)","page":"Parallel & Distributed Sampling","title":"Distributed Sampling (Multi-process)","text":"To perform distributed sampling, start Julia with the -p <n_processes> argument.\n\nEnsure all functions and modules are available on all processes using @everywhere:\n\n@everywhere begin\n    using JuliaBUGS, LogDensityProblems, AbstractMCMC, AdvancedHMC, MCMCChains, ADTypes, ReverseDiff\n\n    # Define any custom functions here\n    # Use `@bugs_primitive` to register functions for use in the model\nend\n\nn_chains = nprocs() - 1  # use all worker processes\nsamples_and_stats = AbstractMCMC.sample(\n    model,\n    AdvancedHMC.NUTS(0.65),\n    AbstractMCMC.MCMCDistributed(),\n    n_samples,\n    n_chains;\n    chain_type = Chains,\n    n_adapts = n_adapts,\n    init_params = [initial_θ for _ = 1:n_chains],\n    discard_initial = n_adapts,\n    progress = false,  # progress logging can cause issues in distributed mode\n)\n\nThe key differences:\n\nAbstractMCMC.MCMCDistributed(): enables distributed sampling\nprogress = false: recommended to avoid TTY issues in distributed settings","category":"section"},{"location":"api/functions/","page":"Functions","title":"Functions","text":"Most of the functions from BUGS have been implemented. \n\nJuliaBUGS directly utilizes functions from the Julia Standard Library when they share the same names and functionalities. For functions not available in the Julia Standard Library and other popular libraries, we have developed equivalents within JuliaBUGS.BUGSPrimitives.","category":"section"},{"location":"api/functions/#Function-defined-in-Julia-Standard-Library","page":"Functions","title":"Function defined in Julia Standard Library","text":"warning: No keyword arguments syntax in BUGS\nPlease note that some functions listed may accept additional arguments (e.g. trunc) and/or keyword arguments (e.g. sum, sort, mean). However, at the moment JuliaBUGS only supports function arguments of type Real or AbstractArray{Real}. Furthermore, JuliaBUGS does not accommodate the use of keyword argument syntax. Thus, the default values for any optional or keyword arguments will be automatically applied.","category":"section"},{"location":"api/functions/#Function-defined-in-[LogExpFunctions](https://github.com/JuliaStats/LogExpFunctions.jl)","page":"Functions","title":"Function defined in LogExpFunctions","text":"","category":"section"},{"location":"api/functions/#Function-defined-in-JuliaBUGS.BUGSPrimitives","page":"Functions","title":"Function defined in JuliaBUGS.BUGSPrimitives","text":"","category":"section"},{"location":"api/functions/#Base.abs","page":"Functions","title":"Base.abs","text":"abs(x)\n\nThe absolute value of x.\n\nWhen abs is applied to signed integers, overflow may occur, resulting in the return of a negative value. This overflow occurs only when abs is applied to the minimum representable value of a signed integer. That is, when x == typemin(typeof(x)), abs(x) == x < 0, not -x as might be expected.\n\nSee also: abs2, unsigned, sign.\n\nExamples\n\njulia> abs(-3)\n3\n\njulia> abs(1 + im)\n1.4142135623730951\n\njulia> abs.(Int8[-128 -127 -126 0 126 127])  # overflow at typemin(Int8)\n1×6 Matrix{Int8}:\n -128  127  126  0  126  127\n\njulia> maximum(abs, [1, -2, 3, -4])\n4\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#Base.exp-Tuple{Real}","page":"Functions","title":"Base.exp","text":"exp(x)\n\nCompute the natural base exponential of x, in other words ℯ^x.\n\nSee also exp2, exp10 and cis.\n\nExamples\n\njulia> exp(1.0)\n2.718281828459045\n\njulia> exp(im * pi) ≈ cis(pi)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.log-Tuple{Number}","page":"Functions","title":"Base.log","text":"log(x)\n\nCompute the natural logarithm of x.\n\nThrow a DomainError for negative Real arguments. Use Complex arguments to obtain Complex results.\n\nnote: Branch cut\nlog has a branch cut along the negative real axis; -0.0im is taken to be below the axis.\n\nSee also ℯ, log1p, log2, log10.\n\nExamples\n\njulia> log(2)\n0.6931471805599453\n\njulia> log(-3)\nERROR: DomainError with -3.0:\nlog was called with a negative real argument but will only return a complex result if called with a complex argument. Try log(Complex(x)).\nStacktrace:\n [1] throw_complex_domainerror(::Symbol, ::Float64) at ./math.jl:31\n[...]\n\njulia> log(-3 + 0im)\n1.0986122886681098 + 3.141592653589793im\n\njulia> log(-3 - 0.0im)\n1.0986122886681098 - 3.141592653589793im\n\njulia> log.(exp.(-1:1))\n3-element Vector{Float64}:\n -1.0\n  0.0\n  1.0\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.sqrt-Tuple{Real}","page":"Functions","title":"Base.sqrt","text":"sqrt(x)\n\nReturn sqrtx.\n\nThrow a DomainError for negative Real arguments. Use Complex negative arguments instead to obtain a Complex result.\n\nThe prefix operator √ is equivalent to sqrt.\n\nnote: Branch cut\nsqrt has a branch cut along the negative real axis; -0.0im is taken to be below the axis.\n\nSee also: hypot.\n\nExamples\n\njulia> sqrt(big(81))\n9.0\n\njulia> sqrt(big(-81))\nERROR: DomainError with -81.0:\nNaN result for non-NaN input.\nStacktrace:\n [1] sqrt(::BigFloat) at ./mpfr.jl:501\n[...]\n\njulia> sqrt(big(complex(-81)))\n0.0 + 9.0im\n\njulia> sqrt(-81 - 0.0im)  # -0.0im is below the branch cut\n0.0 - 9.0im\n\njulia> .√(1:4)\n4-element Vector{Float64}:\n 1.0\n 1.4142135623730951\n 1.7320508075688772\n 2.0\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.trunc","page":"Functions","title":"Base.trunc","text":"trunc([T,] x)\ntrunc(x; digits::Integer= [, base = 10])\ntrunc(x; sigdigits::Integer= [, base = 10])\n\ntrunc(x) returns the nearest integral value of the same type as x whose absolute value is less than or equal to the absolute value of x.\n\ntrunc(T, x) converts the result to type T, throwing an InexactError if the truncated value is not representable a T.\n\nKeywords digits, sigdigits and base work as for round.\n\nTo support trunc for a new type, define Base.round(x::NewType, ::RoundingMode{:ToZero}).\n\nSee also: %, floor, unsigned, unsafe_trunc.\n\nExamples\n\njulia> trunc(2.22)\n2.0\n\njulia> trunc(-2.22, digits=1)\n-2.2\n\njulia> trunc(Int, -2.22)\n-2\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#Base.min-Tuple{Real, Real}","page":"Functions","title":"Base.min","text":"min(x, y, ...)\n\nReturn the minimum of the arguments, with respect to isless. If any of the arguments is missing, return missing. See also the minimum function to take the minimum element from a collection.\n\nExamples\n\njulia> min(2, 5, 1)\n1\n\njulia> min(4, missing, 6)\nmissing\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.max-Tuple{Real, Real}","page":"Functions","title":"Base.max","text":"max(x, y, ...)\n\nReturn the maximum of the arguments, with respect to isless. If any of the arguments is missing, return missing. See also the maximum function to take the maximum element from a collection.\n\nExamples\n\njulia> max(2, 5, 1)\n5\n\njulia> max(5, missing, 6)\nmissing\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.sum-Tuple{AbstractArray}","page":"Functions","title":"Base.sum","text":"sum(A::AbstractArray; dims)\n\nSum elements of an array over the given dimensions.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Matrix{Int64}:\n 1  2\n 3  4\n\njulia> sum(A, dims=1)\n1×2 Matrix{Int64}:\n 4  6\n\njulia> sum(A, dims=2)\n2×1 Matrix{Int64}:\n 3\n 7\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.sort-Tuple{AbstractArray}","page":"Functions","title":"Base.sort","text":"sort(A; dims::Integer, alg::Base.Sort.Algorithm=Base.Sort.defalg(A), lt=isless, by=identity, rev::Bool=false, order::Base.Order.Ordering=Base.Order.Forward)\n\nSort a multidimensional array A along the given dimension. See sort! for a description of possible keyword arguments.\n\nTo sort slices of an array, refer to sortslices.\n\nExamples\n\njulia> A = [4 3; 1 2]\n2×2 Matrix{Int64}:\n 4  3\n 1  2\n\njulia> sort(A, dims = 1)\n2×2 Matrix{Int64}:\n 1  2\n 4  3\n\njulia> sort(A, dims = 2)\n2×2 Matrix{Int64}:\n 3  4\n 1  2\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.sin-Tuple{Real}","page":"Functions","title":"Base.sin","text":"sin(x::T) where {T <: Number} -> float(T)\n\nCompute sine of x, where x is in radians.\n\nThrow a DomainError if isinf(x), return a T(NaN) if isnan(x).\n\nSee also sind, sinpi, sincos, cis, asin.\n\nExamples\n\njulia> round.(sin.(range(0, 2pi, length=9)'), digits=3)\n1×9 Matrix{Float64}:\n 0.0  0.707  1.0  0.707  0.0  -0.707  -1.0  -0.707  -0.0\n\njulia> sind(45)\n0.7071067811865476\n\njulia> sinpi(1/4)\n0.7071067811865475\n\njulia> round.(sincos(pi/6), digits=3)\n(0.5, 0.866)\n\njulia> round(cis(pi/6), digits=3)\n0.866 + 0.5im\n\njulia> round(exp(im*pi/6), digits=3)\n0.866 + 0.5im\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.cos-Tuple{Real}","page":"Functions","title":"Base.cos","text":"cos(x::T) where {T <: Number} -> float(T)\n\nCompute cosine of x, where x is in radians.\n\nThrow a DomainError if isinf(x), return a T(NaN) if isnan(x).\n\nSee also cosd, cospi, sincos, cis.\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.tan-Tuple{Real}","page":"Functions","title":"Base.tan","text":"tan(x::T) where {T <: Number} -> float(T)\n\nCompute tangent of x, where x is in radians.\n\nThrow a DomainError if isinf(x), return a T(NaN) if isnan(x).\n\nSee also tanh.\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.asin-Tuple{Real}","page":"Functions","title":"Base.asin","text":"asin(x::T) where {T <: Number} -> float(T)\n\nCompute the inverse sine of x, where the output is in radians.\n\nReturn a T(NaN) if isnan(x).\n\nSee also asind for output in degrees.\n\nExamples\n\njulia> asin.((0, 1/2, 1))\n(0.0, 0.5235987755982989, 1.5707963267948966)\n\njulia> asind.((0, 1/2, 1))\n(0.0, 30.000000000000004, 90.0)\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.acos-Tuple{Real}","page":"Functions","title":"Base.acos","text":"acos(x::T) where {T <: Number} -> float(T)\n\nCompute the inverse cosine of x, where the output is in radians\n\nReturn a T(NaN) if isnan(x).\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.atan-Tuple{Real}","page":"Functions","title":"Base.atan","text":"atan(y)\natan(y, x)\n\nCompute the inverse tangent of y or y/x, respectively.\n\nFor one real argument, this is the angle in radians between the positive x-axis and the point (1, y), returning a value in the interval -pi2 pi2.\n\nFor two arguments, this is the angle in radians between the positive x-axis and the point (x, y), returning a value in the interval -pi pi. This corresponds to a standard atan2 function. Note that by convention atan(0.0,x) is defined as pi and atan(-0.0,x) is defined as -pi when x < 0.\n\nSee also atand for degrees.\n\nExamples\n\njulia> rad2deg(atan(-1/√3))\n-30.000000000000004\n\njulia> rad2deg(atan(-1, √3))\n-30.000000000000004\n\njulia> rad2deg(atan(1, -√3))\n150.0\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.asinh-Tuple{Real}","page":"Functions","title":"Base.asinh","text":"asinh(x)\n\nCompute the inverse hyperbolic sine of x.\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.acosh-Tuple{Real}","page":"Functions","title":"Base.acosh","text":"acosh(x)\n\nCompute the inverse hyperbolic cosine of x.\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Base.atanh-Tuple{Real}","page":"Functions","title":"Base.atanh","text":"atanh(x)\n\nCompute the inverse hyperbolic tangent of x.\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#Statistics.mean-Tuple{AbstractArray}","page":"Functions","title":"Statistics.mean","text":"mean(A::AbstractArray; dims)\n\nCompute the mean of an array over the given dimensions.\n\ncompat: Julia 1.1\nmean for empty arrays requires at least Julia 1.1.\n\nExamples\n\njulia> using Statistics\n\njulia> A = [1 2; 3 4]\n2×2 Matrix{Int64}:\n 1  2\n 3  4\n\njulia> mean(A, dims=1)\n1×2 Matrix{Float64}:\n 2.0  3.0\n\njulia> mean(A, dims=2)\n2×1 Matrix{Float64}:\n 1.5\n 3.5\n\n\n\n\n\n","category":"method"},{"location":"api/functions/#LogExpFunctions.cloglog","page":"Functions","title":"LogExpFunctions.cloglog","text":"cloglog(x)\n\n\nCompute the complementary log-log, log(-log(1 - x)).\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#LogExpFunctions.cexpexp","page":"Functions","title":"LogExpFunctions.cexpexp","text":"cexpexp(x)\n\n\nCompute the complementary double exponential, 1 - exp(-exp(x)).\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#LogExpFunctions.logit","page":"Functions","title":"LogExpFunctions.logit","text":"logit(x)\n\n\nThe logit or log-odds transformation, defined as\n\noperatornamelogit(x) = logleft(fracx1-xright)\n\nfor 0  x  1.\n\nIts inverse is the logistic function.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#LogExpFunctions.logistic","page":"Functions","title":"LogExpFunctions.logistic","text":"logistic(x)\n\n\nThe logistic sigmoid function mapping a real number to a value in the interval 01,\n\nsigma(x) = frac1e^-x + 1 = frace^x1+e^x\n\nIts inverse is the logit function.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.equals","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.equals","text":"equals(x, y)\n\nReturns 1 if x is equal to y, 0 otherwise.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.inprod","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.inprod","text":"inprod(a, b)\n\nInner product of a and b.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.inverse","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.inverse","text":"inverse(m::AbstractMatrix)\n\nInverse of matrix mathbfm.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.logdet","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.logdet","text":"logdet(::AbstractMatrix)\n\nLogarithm of the determinant of matrix mathbfv.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.logfact","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.logfact","text":"logfact(x)\n\nLogarithm of the factorial of x.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.loggam","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.loggam","text":"loggam(x)\n\nLogarithm of the gamma function of x.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.icloglog","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.icloglog","text":"icloglog(x)\n\nInverse complementary log-log function of x. Alias for cexpexp(x).\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.ilogit","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.ilogit","text":"ilogit(x)\n\nInverse logit function of x. Alias for logistic(x).\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.mexp","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.mexp","text":"mexp(x::AbstractMatrix)\n\nMatrix exponential of mathbfx.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.phi","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.phi","text":"phi(x)\n\nCumulative distribution function (CDF) of the standard normal distribution evaluated at x.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.probit","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.probit","text":"probit\n\nInverse of phi.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.pow","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.pow","text":"pow(a, b)\n\nReturn a raised to the power of b.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.rank","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.rank","text":"rank(v::AbstractVector, i::Integer)\n\nReturn the rank of the i-th element of mathbfv.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.ranked","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.ranked","text":"ranked(v::AbstractVector, i::Integer)\n\nReturn the i-th element of mathbfv sorted in ascending order.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.sd","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.sd","text":"sd(v::AbstractVector)\n\nReturn the standard deviation of the input vector mathbfv.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.softplus","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.softplus","text":"softplus(x)\n\nReturn the softplus function of x, defined as log(1 + exp(x)).\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives._step","page":"Functions","title":"JuliaBUGS.BUGSPrimitives._step","text":"_step(x)\n\nReturn 1 if x is greater than 0, and 0 otherwise.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.arcsin","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.arcsin","text":"arcsin(x)\n\nSee asin.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.arcsinh","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.arcsinh","text":"arcsinh(x)\n\nSee asinh.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.arccos","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.arccos","text":"arccos(x)\n\nSee acos.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.arccosh","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.arccosh","text":"arccosh(x)\n\nSee acosh.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.arctan","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.arctan","text":"arctan(x)\n\nSee atan.\n\n\n\n\n\n","category":"function"},{"location":"api/functions/#JuliaBUGS.BUGSPrimitives.arctanh","page":"Functions","title":"JuliaBUGS.BUGSPrimitives.arctanh","text":"arctanh(x)\n\nSee atanh.\n\n\n\n\n\n","category":"function"},{"location":"guides/pitfalls/#Understanding-Pitfalls-in-Model-Definitions","page":"Pitfalls","title":"Understanding Pitfalls in Model Definitions","text":"","category":"section"},{"location":"guides/pitfalls/#Consequence-of-Observations-on-Model-Parameters","page":"Pitfalls","title":"Consequence of Observations on Model Parameters","text":"When providing observations for the parameters of a model, the dependencies may become disrupted. Consider the following example written in Julia:\n\nmodel_def = @bugs begin\n    a ~ Normal(0, 1)\n    b ~ Normal(0, 1)\n    c ~ Normal(a, b)\nend\n\ndata = (a=1.0, b=2.0)\n\nIn this scenario, the generated graph will lack the edges a -> c and b -> c, leading the node function of c to become c ~ Normal(1.0, 2.0).","category":"section"},{"location":"guides/pitfalls/#Ambiguity-Between-Constants-and-Observations","page":"Pitfalls","title":"Ambiguity Between Constants and Observations","text":"A subtle and possibly contentious feature of BUGS syntax is that the observation value of a stochastic variable is treated identically to any model parameters supplied in the data. The following example is legal in BUGS if N is provided as data:\n\nmodel {\n    N ~ dcat(p[])\n    for (i in 1:N) {\n        y[i] ~ dnorm(mu, tau)\n    }\n    p[1] <- 0.5\n    p[2] <- 0.5\n}","category":"section"},{"location":"guides/tricks/#BUGS-Implementation-Tricks","page":"Implementation Tricks","title":"BUGS Implementation Tricks","text":"","category":"section"},{"location":"guides/tricks/#Implementing-Custom-Distributions-Without-Low-Level-Coding-in-Previous-Version-of-BUGS","page":"Implementation Tricks","title":"Implementing Custom Distributions Without Low-Level Coding in Previous Version of BUGS","text":"In JuliaBUGS, users can simply create new distributions using the Distributions.jl interface and use them as built-in distributions. In previous versions of BUGS, defining new distributions required lower-level programming, as users needed to work directly with the underlying implementation.\n\nHere we present some of the tricks that were used in previous BUGS implementations to create custom distributions without implementing them directly at the low level. These approaches are still valid in JuliaBUGS, though the native distribution interface is generally preferred.","category":"section"},{"location":"guides/tricks/#The-\"Zeros-Trick\"","page":"Implementation Tricks","title":"The \"Zeros Trick\"","text":"When you need a distribution not included in the standard set, the \"zeros trick\" offers an elegant solution. This technique leverages the fact that a Poisson observation with mean phi and value 0 has likelihood e^-phi.\n\nHow it works:\n\nCreate artificial data points of zeros\nSet phii = -log(Li) + C, where:\nLi\nis your desired likelihood term\nC\nis a constant large enough to ensure phii  0\n\nImplementation:\n\nC <- 10000    # Large constant ensuring phi[i] > 0\n\nfor (i in 1:N) {\n    zeros[i] <- 0\n    phi[i] <- -log(L[i]) + C\n    zeros[i] ~ dpois(phi[i])\n}\n\nThis method is particularly useful for implementing truncated distributions or any arbitrary likelihood function.","category":"section"},{"location":"guides/tricks/#The-\"Ones-Trick\"","page":"Implementation Tricks","title":"The \"Ones Trick\"","text":"An alternative approach uses Bernoulli observations fixed at 1:\n\nHow it works:\n\nCreate artificial data points of ones\nDefine probabilities proportional to your desired likelihood: pi = fracLiC\nChoose C large enough to ensure pi  1\n\nImplementation:\n\nC <- 10000    # Large constant ensuring p[i] < 1\n\nfor (i in 1:N) {\n    ones[i] <- 1\n    p[i] <- L[i] / C\n    ones[i] ~ dbern(p[i])\n}","category":"section"},{"location":"guides/tricks/#Using-dloglik-in-OpenBUGS-and-MultiBUGS","page":"Implementation Tricks","title":"Using dloglik in OpenBUGS and MultiBUGS","text":"The dloglik distribution provides a more direct approach for implementing custom likelihoods:\n\ndummy[i] <- 0\ndummy[i] ~ dloglik(logLike[i])\n\nWhere logLike[i] is the log-likelihood contribution for observation i. This essentially implements the \"zeros trick\" behind the scenes.\n\nExample: Manual Normal Likelihood Implementation\n\nmodel {\n   for (i in 1:7) {\n      dummy[i] <- 0\n      dummy[i] ~ dloglik(logLike[i])\n      logLike[i] <- -log(sigma) - 0.5 * pow((x[i] - mu)/sigma, 2)         \n   }\n   mu ~ dunif(-10, 10)\n   sigma ~ dunif(0, 10)\n}\n\nStandard equivalent:\n\nmodel {\n   for (i in 1:7) {\n      x[i] ~ dnorm(mu, prec)\n   }\n   prec <- 1 / (sigma * sigma)\n   mu ~ dunif(-10, 10)\n   sigma ~ dunif(0, 10)\n}","category":"section"},{"location":"guides/tricks/#Implementing-Custom-Prior-Distributions","page":"Implementation Tricks","title":"Implementing Custom Prior Distributions","text":"You can use dloglik to implement non-standard prior distributions:\n\ntheta ~ dflat()           # Use flat improper prior as base\ndummy <- 0\ndummy ~ dloglik(logLike)  # Add custom prior via log-likelihood\nlogLike <- log(desired_prior_for_theta)\n\nExample: Manual Normal Prior Implementation\n\nmodel {\n   for (i in 1:7) {\n      x[i] ~ dnorm(mu, prec)\n   }\n   dummy <- 0\n   dummy ~ dloglik(phi)\n   phi <- -0.5 * pow(mu, 2)  # log(N(0,1))\n   mu ~ dflat()              # Base distribution\n   prec <- 1 / (sigma * sigma)\n   sigma ~ dunif(0, 10)\n}\n\nStandard equivalent:\n\nmodel {\n   for (i in 1:7) {\n      x[i] ~ dnorm(mu, prec)\n   }\n   mu ~ dnorm(0, 1)\n   prec <- 1 / (sigma * sigma)\n   sigma ~ dunif(0, 10)\n}\n\nNote: Using dloglik for priors may trigger Metropolis sampling, potentially leading to slower convergence and higher Monte Carlo errors.","category":"section"},{"location":"guides/tricks/#Working-with-Predictions-and-Complex-Models","page":"Implementation Tricks","title":"Working with Predictions and Complex Models","text":"","category":"section"},{"location":"guides/tricks/#Predicting-New-Observations","page":"Implementation Tricks","title":"Predicting New Observations","text":"To generate predictions for a new observation x.pred, specify it as missing and assign an improper uniform prior:\n\nx.pred ~ dflat()  # Improper uniform prior\n\nBe aware this approach may increase computational inefficiency and Monte Carlo error.","category":"section"},{"location":"guides/tricks/#Handling-Model-Mixtures-of-Different-Complexity","page":"Implementation Tricks","title":"Handling Model Mixtures of Different Complexity","text":"For mixture models with components of varying complexity, a standard mixture distribution approach is often sufficient without requiring reversible jump techniques:\n\nmodel {\n   mu ~ dunif(-5, 5)\n   p ~ dunif(0, 1)\n   m[1] <- 0       # First component mean\n   m[2] <- mu      # Second component mean\n   \n   for (i in 1:100) {\n      group[i] ~ dbern(p)           # Component membership\n      index[i] <- group[i] + 1\n      y[i] ~ dnorm(m[index[i]], 1)  # Observation from selected component\n   }\n}","category":"section"},{"location":"guides/tricks/#Managing-Random-Set-Sizes","page":"Implementation Tricks","title":"Managing Random Set Sizes","text":"When loop bounds depend on random quantities (e.g., changepoints), use step functions to conditionally include elements:\n\nfor (i in 1:N) {\n   ind[i] <- 1 + step(i - K - 0.01)  # 1 if i ≤ K, 2 if i > K\n   y[i] ~ model[ind[i]]              # Select appropriate model\n}\n\nExample: Computing the Sum of First K Integers\n\nmodel {\n   # Define possible values for K\n   for (i in 1:10) {\n      p[i] <- 1/10  # Equal probability for each value\n      x[i] <- i     # Value i\n   }\n   \n   # Random selection of K\n   K ~ dcat(p[])\n   \n   # Sum elements conditionally\n   for (i in 1:10) {\n      xtosum[i] <- x[i] * step(K - i + 0.01)  # Include x[i] only if i ≤ K\n   }\n   \n   # Compute final sum\n   s <- sum(xtosum[])\n}","category":"section"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dnorm","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dnorm","text":"dnorm(μ, τ)\n\nReturns an instance of Normal  with mean μ and standard deviation frac1τ. \n\np(xμτ) = sqrtfracτ2π e^-τ frac(x-μ)^22\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dlogis","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dlogis","text":"dlogis(μ, τ)\n\nReturn an instance of Logistic  with location parameter μ and scale parameter frac1τ.\n\np(xμτ) = fracsqrtτ e^-sqrtτ(x-μ)(1+e^-sqrtτ(x-μ))^2\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dt","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dt","text":"dt(μ, τ, ν)\n\nIf μ = 0 and σ = 1, the function returns an instance of TDist  with ν degrees of freedom, location μ, and scale σ = frac1sqrtτ. Otherwise, it returns an instance of TDistShiftedScaled.\n\np(xνμσ) = fracΓ((ν+1)2)Γ(ν2) sqrtνπσ\nleft(1+frac1νleft(fracx-μσright)^2right)^-fracν+12\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.TDistShiftedScaled","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.TDistShiftedScaled","text":"TDistShiftedScaled(ν, μ, σ)\n\nStudent's t-distribution with ν degrees of freedom, location μ, and scale σ. \n\nThis struct allows for a shift (determined by μ) and a scale (determined by σ) of the standard  Student's t-distribution provided by the Distributions.jl  package. \n\nOnly pdf and logpdf are implemented for this distribution.\n\nSee Also\n\nTDist\n\n\n\n\n\n","category":"type"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.ddexp","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.ddexp","text":"ddexp(μ, τ)\n\nReturn an instance of Laplace (Double Exponential)  with location μ and scale frac1sqrtτ.\n\np(xμτ) = fracsqrtτ2 e^-sqrtτ x-μ\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dflat","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dflat","text":"dflat()\n\nReturns an instance of Flat or TruncatedFlat if truncated.\n\nFlat represents a flat (uniform) prior over the real line, which is an improper distribution. And  TruncatedFlat represents a truncated version of the Flat distribution.\n\nOnly pdf, logpdf, minimum, and maximum are implemented for these Distributions.\n\nWhen use in a model, the parameters always need to be initialized.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.Flat","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.Flat","text":"Flat\n\nThe flat distribution mimicking the behavior of the dflat distribution in the BUGS family of softwares.\n\n\n\n\n\n","category":"type"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.TruncatedFlat","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.TruncatedFlat","text":"TruncatedFlat\n\nTruncated version of the Flat distribution.\n\n\n\n\n\n","category":"type"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dexp","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dexp","text":"dexp(λ)\n\nReturns an instance of Exponential  with rate frac1λ.\n\np(xλ) = λ e^-λ x\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dchisqr","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dchisqr","text":"dchisqr(k)\n\nReturns an instance of Chi-squared  with k degrees of freedom.\n\np(xk) = frac12^k2 Γ(k2) x^k2 - 1 e^-x2\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dweib","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dweib","text":"dweib(a, b)\n\nReturns an instance of Weibull  distribution object with shape parameter a and scale parameter frac1b.\n\nThe Weibull distribution is a common model for event times. The hazard or instantaneous risk of the event  is abx^a-1. For a  1 the hazard decreases with x; for a  1 it increases.  a = 1 results in the exponential distribution with constant hazard.\n\np(xab) = abx^a-1e^-b x^a\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dlnorm","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dlnorm","text":"dlnorm(μ, τ)\n\nReturns an instance of LogNormal  with location μ and scale frac1sqrtτ.\n\np(xμτ) = fracsqrtτxsqrt2π e^-τ2 (log(x) - μ)^2\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dgamma","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dgamma","text":"dgamma(a, b)\n\nReturns an instance of Gamma  with shape a and scale frac1b.\n\np(xab) = fracb^aΓ(a) x^a-1 e^-bx\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dpar","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dpar","text":"dpar(a, b)\n\nReturns an instance of Pareto  with scale parameter b and shape parameter a.\n\np(xab) = fraca b^ax^a+1\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dgev","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dgev","text":"dgev(μ, σ, η)\n\nReturns an instance of GeneralizedExtremeValue  with location μ, scale σ, and shape η.\n\np(xμση) = frac1σ left(1 + η fracx - μσright)^-frac1η - 1 e^-left(1 + η fracx - μσright)^-frac1η\n\nwhere fracη(x - μ)σ  -1.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dgpar","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dgpar","text":"dgpar(μ, σ, η)\n\nReturns an instance of GeneralizedPareto  with location μ, scale σ, and shape η.\n\np(xμση) = frac1σ (1 + η ((x - μ)σ))^-1η - 1\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.df","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.df","text":"df(n, m, μ=0, τ=1)\n\nReturns an instance of F-distribution  object with n and m degrees of freedom, location μ, and scale τ. This function is only valid when μ = 0 and τ = 1,\n\np(xn m μ τ) = fracGammaleft(fracn+m2right)Gammaleft(fracn2right) Gammaleft(fracm2right) left(fracnmright)^fracn2 sqrtτ left(sqrtτ(x - μ)right)^fracn2-1 left(1 + fracn sqrtτ(x-μ)mright)^-fracn+m2\n\nwhere fracn sqrtτ (x - μ)m  -1.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dunif","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dunif","text":"dunif(a, b)\n\nReturns an instance of Uniform  with lower bound a and upper bound b.\n\np(xab) = frac1b - a\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dbeta","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dbeta","text":"dbeta(a, b)\n\nReturns an instance of Beta  with shape parameters a and b.\n\np(xab) = fracGamma(a + b)Gamma(a)Gamma(b) x^a-1 (1 - x)^b-1\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dmnorm","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dmnorm","text":"dmnorm(μ::AbstractVector, T::AbstractMatrix)\n\nReturns an instance of Multivariate Normal  with mean vector μ and covariance matrix T^-1.\n\np(xμT) = (2π)^-k2 T^12 e^-12 (x-μ) T (x-μ)\n\nwhere k is the dimension of x.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dmt","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dmt","text":"dmt(μ::AbstractVector, T::AbstractMatrix, k)\n\nReturns an instance of Multivariate T  with mean vector μ, scale matrix T^-1, and k degrees of freedom.\n\np(xkμΣ) = fracGamma((k+d)2)Gamma(k2) (kpi)^p2 Σ^12 left(1 + frac1k (x-μ)^T Σ^-1 (x-μ)right)^-frack+p2\n\nwhere p is the dimension of x.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dwish","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dwish","text":"dwish(R::AbstractMatrix, k)\n\nReturns an instance of Wishart  with k degrees of freedom and the scale matrix T^-1.\n\np(XRk) = R^k2 X^(k-p-1)2 e^-(12) tr(RX)  (2^kp2 Γ_p(k2))\n\nwhere p is the dimension of X, and it should be less than or equal to k. \n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.ddirich","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.ddirich","text":"ddirich(θ::AbstractVector)\n\nReturn an instance of Dirichlet  with parameters θ_i.\n\np(xθ) = fracΓ(sum θ) Γ(θ)  x_i^θ_i - 1\n\nwhere theta_i  0 x_i in 0 1 sum_i x_i = 1\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dbern","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dbern","text":"dbern(p)\n\nReturn an instance of Bernoulli  with success probability p.\n\np(xp) = p^x (1 - p)^1-x\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dbin","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dbin","text":"dbin(p, n)\n\nReturns an instance of Binomial  with number of trials n and success probability p.\n\np(xnp) = binomnx p^x (1 - p)^n-x\n\nend\n\nwhere theta in 0 1 n in mathbbZ^+ and x = 0 ldots n.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dcat","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dcat","text":"dcat(p)\n\nReturns an instance of Categorical  with probabilities p.\n\np(xp) = px\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dpois","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dpois","text":"dpois(θ)\n\nReturns an instance of Poisson  with mean (and variance) θ.\n\np(xθ) = e^-θ θ^x  x\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dgeom","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dgeom","text":"dgeom(θ)\n\nReturns an instance of Geometric  with success probability θ.\n\np(xθ) = (1 - θ)^x-1 θ\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dnegbin","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dnegbin","text":"dnegbin(p, r)\n\nReturns an instance of Negative Binomial  with number of failures r and success probability p.\n\nP(xrp) = binomx + r - 1x (1 - p)^x p^r\n\nwhere x in mathbbZ^+.\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dbetabin","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dbetabin","text":"dbetabin(a, b, n)\n\nReturns an instance of Beta Binomial  with number of trials n and shape parameters a and b.\n\nP(xa b n) = fracbinomnx binoma + b - 1a + x - 1binoma + b + n - 1n\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dhyper","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dhyper","text":"dhyper(n₁, n₂, m₁, ψ=1)\n\nReturns an instance of Hypergeometric.  This distribution is used when sampling without replacement from a population consisting of  n₁ successes and n₂ failures, with m₁ being the number of trials or the sample size.  The function currently only allows for ψ = 1.\n\np(x  n₁ n₂ m₁ psi) = fracbinomn₁x binomn₂m₁ - x psi^xsum_i=u_0^u_1 binomn1i binomn2m₁ - i psi^i\n\nwhere u_0 = max(0 m₁-n₂) u_1 = min(n₁m₁) and u_0 leq x leq u_1\n\n\n\n\n\n","category":"function"},{"location":"api/distributions/#JuliaBUGS.BUGSPrimitives.dmulti","page":"Distributions","title":"JuliaBUGS.BUGSPrimitives.dmulti","text":"dmulti(θ::AbstractVector, n)\n\nReturns an instance Multinomial  with number of trials n and success probabilities θ.\n\nP(xnθ) = fracn_r x_r _r θ_r^x_r\n\n\n\n\n\n","category":"function"},{"location":"graph_plotting/#Plotting-graphs","page":"Plotting","title":"Plotting graphs","text":"Plotting the graphical model can be very beneficial for debugging the model.\n\nnote: Plate notation is not yet supported\nUsers are advised to begin with a model that contains fewer nodes, so that the graph is easier to visualize.\n\nWe have set up standard plotting routines with GraphMakie.jl and GraphPlot.jl, via package extensions.\n\nObserved nodes are colored in gray, unobserved nodes are colored in white, and deterministic nodes are colored in light blue.\n\nmodel_def = @bugs begin\n    a ~ dnorm(f, c)\n    f = b - 1\n    b ~ dnorm(0, 1)\n    c ~ dnorm(l, 1)\n    g = a * 2\n    d ~ dnorm(g, 1)\n    h = g + 2\n    e ~ dnorm(h, i)\n    i ~ dnorm(0, 1)\n    l ~ dnorm(0, 1)\nend\n\ndata = (\n    e = 5.0,\n)\n\ninits = (\n    a = 1.0,\n    b = 2.0,\n    c = 3.0,\n    d = 4.0,\n    i = 4.0,\n    l = -2.0,\n)\n\nmodel = compile(model_def, data, inits)","category":"section"},{"location":"graph_plotting/#[GraphPlot.jl](https://github.com/JuliaGraphs/GraphPlot.jl)","page":"Plotting","title":"GraphPlot.jl","text":"using GraphPlot\ngplot(model)\n\n(Image: GraphPlot)","category":"section"},{"location":"graph_plotting/#[GraphMakie.jl](https://github.com/MakieOrg/GraphMakie.jl)","page":"Plotting","title":"GraphMakie.jl","text":"using GLMakie, GraphMakie\ngraphplot(model)\n\n(Image: GraphMakie)","category":"section"},{"location":"inference/ad/#Automatic-Differentiation","page":"Automatic Differentiation","title":"Automatic Differentiation","text":"JuliaBUGS integrates with automatic differentiation (AD) through DifferentiationInterface.jl, enabling gradient-based inference methods like Hamiltonian Monte Carlo (HMC) and No-U-Turn Sampler (NUTS).","category":"section"},{"location":"inference/ad/#Specifying-an-AD-Backend","page":"Automatic Differentiation","title":"Specifying an AD Backend","text":"To compile a model with gradient support, pass the adtype parameter to compile:\n\n# Compile with gradient support using ADTypes from ADTypes.jl\nusing ADTypes\nmodel = compile(model_def, data; adtype=AutoReverseDiff(compile=true))\n\nAlternatively, if you already have a compiled BUGSModel, you can wrap it with BUGSModelWithGradient without recompiling:\n\nbase_model = compile(model_def, data)\nmodel = BUGSModelWithGradient(base_model, AutoReverseDiff(compile=true))","category":"section"},{"location":"inference/ad/#Available-AD-Backends","page":"Automatic Differentiation","title":"Available AD Backends","text":"Backend When to use\nAutoReverseDiff(compile=true) Recommended for most models\nAutoReverseDiff(compile=false) Models with control flow\nAutoForwardDiff() Small models (< 20 parameters)\nAutoMooncake() With UseGeneratedLogDensityFunction() mode\n\nThe compiled model with gradient support implements the LogDensityProblems.jl interface, including logdensity_and_gradient, which returns both the log density and its gradient.","category":"section"},{"location":"inference/ad/#AD-Backends-with-UseGraph()-Mode","page":"Automatic Differentiation","title":"AD Backends with UseGraph() Mode","text":"Use ReverseDiff.jl or ForwardDiff.jl with the default UseGraph() mode:\n\nusing ADTypes\n\n# ReverseDiff with tape compilation (recommended for large models)\nmodel = compile(model_def, data; adtype=AutoReverseDiff(compile=true))\n\n# ForwardDiff (efficient for small models with < 20 parameters)\nmodel = compile(model_def, data; adtype=AutoForwardDiff())\n\n# ReverseDiff without compilation (supports control flow)\nmodel = compile(model_def, data; adtype=AutoReverseDiff(compile=false))\n\nnote: Control flow and compiled tapes\nBUGS syntax is declarative and doesn't include control flow (if, while), so most models work fine with compiled tapes. However, if you register custom functions via @bugs_primitive that internally use control flow, the compiled tape will only capture one execution path. In such cases, use AutoReverseDiff(compile=false) or AutoForwardDiff() instead.","category":"section"},{"location":"inference/ad/#AD-Backend-with-UseGeneratedLogDensityFunction()-Mode","page":"Automatic Differentiation","title":"AD Backend with UseGeneratedLogDensityFunction() Mode","text":"Use Mooncake.jl with the generated log density function mode:\n\nusing ADTypes\n\nmodel = compile(model_def, data)\nmodel = set_evaluation_mode(model, UseGeneratedLogDensityFunction())\nmodel = BUGSModelWithGradient(model, AutoMooncake(; config=nothing))\n\nFor more details on evaluation modes, see Evaluation Modes.","category":"section"},{"location":"R_interface/#R-Interface","page":"R Interface","title":"R Interface","text":"RJuliaBUGS lets you run BUGS models from R using Julia's fast sampling algorithms.\n\nCreated by Mateus Maia as part of Google Summer of Code 2025.","category":"section"},{"location":"R_interface/#What-is-RJuliaBUGS?","page":"R Interface","title":"What is RJuliaBUGS?","text":"RJuliaBUGS connects R to JuliaBUGS. You write models in BUGS syntax and run them from R, but they execute using Julia's modern samplers like Hamiltonian Monte Carlo (HMC).\n\nKey benefits:\n\nKeep your existing BUGS models\nRun models faster with Julia's algorithms\nStay in R for all analysis\nWorks with bayesplot, posterior, coda, and other R packages","category":"section"},{"location":"R_interface/#Related-Julia-Packages","page":"R Interface","title":"Related Julia Packages","text":"For R users working with Julia:\n\nRCall.jl - Run R from Julia\nRData.jl - Read/write R data files\nDataFrames.jl - Data manipulation (like dplyr)\nCSV.jl - Work with CSV files\nJSON.jl, JSON3.jl - Work with JSON data","category":"section"},{"location":"two_macros/#Two-Macros:-@bugs-and-@model","page":"Two Macros: @bugs & @model","title":"Two Macros: @bugs and @model","text":"JuliaBUGS provides two macros for defining probabilistic models with different function access policies.","category":"section"},{"location":"two_macros/#@bugs","page":"Two Macros: @bugs & @model","title":"@bugs","text":"The @bugs macro creates model expressions compatible with the BUGS language:\n\nOnly BUGS primitives (dnorm, dgamma, exp, log, etc.) are available\nCustom functions must be registered using @bugs_primitive\nQualified function names (e.g., Base.exp, Distributions.Normal) are not allowed\n\n# Works - uses only BUGS primitives\nmodel_expr = @bugs begin\n    x ~ dnorm(0, 1)\n    y = exp(x)\nend\n\n# To use custom functions, register them first:\nmy_func(x) = x + 1\n@bugs_primitive my_func\n\nmodel_expr = @bugs begin\n    x ~ dnorm(0, 1)\n    y = my_func(x)  # Now works!\nend","category":"section"},{"location":"two_macros/#@model","page":"Two Macros: @bugs & @model","title":"@model","text":"The @model macro creates model-generating functions with full Julia scope:\n\nHas access to all imports and functions in the calling module\nRequires explicit imports of BUGS primitives\nMore flexible for Julia integration\n\nusing JuliaBUGS.BUGSPrimitives: dnorm\n\nmy_transform(x) = x^2 + 1\n\n@model function my_model((; theta))\n    theta ~ dnorm(0, 1)\n    y = my_transform(theta)  # Works - has access to user functions\nend","category":"section"},{"location":"developers/source_gen/#Generating-Sequential-Code-from-BUGS-Program","page":"Source Code Generation","title":"Generating Sequential Code from BUGS Program","text":"","category":"section"},{"location":"developers/source_gen/#Transform-BUGS-Programs-into-Sequential-Programs","page":"Source Code Generation","title":"Transform BUGS Programs into Sequential Programs","text":"JuliaBUGS compiles a BUGS program into a directed probabilistic graphical model. This graphical model also serves as a dependence graph between the variables in the model/program.\n\nWith the dependence graph, the execution of the probabilistic program can be carried out by visiting nodes (variables) in the graph following a topological order. (Parallel computing opportunities are also exposed by exploiting the dependence relationships.)\n\nThe challenge arises because, given the semantics of the BUGS language, every element of an array can be a random variable, thus demanding its own node in the graph. Consequently, naively converting the graph execution into sequential programs would amount to fully unrolling all loops, which is often infeasible, particularly for automatic differentiation (AD) tools.\n\nA potential solution is to transform the user-provided program, which might be out of sequential order, into a correct sequential program. Correctness here is defined as ensuring no variable is read before it is written. \n\nProgram transformation is a well-studied topic. It is known to be very challenging in terms of conceptual understanding, algorithm design, and practical implementation.\n\nTraditionally, program transformation optimizes sequentially valid programs for performance (speed, memory usage) based on hardware characteristics, while respecting data dependencies. \n\nFor JuliaBUGS, it's crucial to clarify that the primary goal is not optimizing the generated program's performance but ensuring its correctness with respect to sequential execution order. The task is to transform a potentially out-of-sequential-order program into a sequentially correct one.\n\nWe aim to restrict ourselves initially and ask: How can we use a minimal set of transformations, starting with just statement reordering, to generate correct sequential programs from BUGS programs that might specify operations out of order? If the original program is already sequentially correct, it should be used directly. Furthermore, we need to provide clear feedback to the user if a transformation is necessary or if the program structure inherently prevents a valid sequential ordering, guiding them on how to rewrite it.\n\nConsider the Rats example:\n\nbegin\n    for i in 1:N\n        for j in 1:T\n            Y[i, j] ~ dnorm(mu[i, j], tau_c)              # (1)\n            mu[i, j] = alpha[i] + beta[i] * (x[j] - xbar)  # (2)\n        end\n        alpha[i] ~ dnorm(alpha_c, alpha_tau)               # (3)\n        beta[i] ~ dnorm(beta_c, beta_tau)                  # (4)\n    end\n    tau_c ~ dgamma(0.001, 0.001)                          # (5)\n    sigma = 1 / sqrt(tau_c)                                # (6)\n    alpha_c ~ dnorm(0.0, 1.0e-6)                           # (7)\n    alpha_tau ~ dgamma(0.001, 0.001)                       # (8)\n    beta_c ~ dnorm(0.0, 1.0e-6)                            # (9)\n    beta_tau ~ dgamma(0.001, 0.001)                        # (10)\n    alpha0 = alpha_c - xbar * beta_c                        # (11)\nend\n\nThis program defines the same probabilistic model (has the same BUGS semantics) as the following two versions:\n\nVersion 1 (Reordered Statements):\n\nbegin\n    tau_c ~ dgamma(0.001, 0.001)                           # (5)\n    sigma = 1 / sqrt(tau_c)                                # (6)\n    alpha_c ~ dnorm(0.0, 1.0e-6)                           # (7)\n    alpha_tau ~ dgamma(0.001, 0.001)                       # (8)\n    beta_c ~ dnorm(0.0, 1.0e-6)                            # (9)\n    beta_tau ~ dgamma(0.001, 0.001)                        # (10)\n    \n    for i in 1:N\n        alpha[i] ~ dnorm(alpha_c, alpha_tau)               # (3)\n        beta[i] ~ dnorm(beta_c, beta_tau)                  # (4)\n        \n        for j in 1:T\n            mu[i, j] = alpha[i] + beta[i] * (x[j] - xbar)  # (2)\n            Y[i, j] ~ dnorm(mu[i, j], tau_c)               # (1)\n        end\n    end\n    \n    alpha0 = alpha_c - xbar * beta_c                       # (11)\nend\n\nVersion 2 (Reordered Statements + Loop Fission):\n\nbegin\n    tau_c ~ dgamma(0.001, 0.001)                           # (5)\n    sigma = 1 / sqrt(tau_c)                                # (6)\n    alpha_c ~ dnorm(0.0, 1.0e-6)                           # (7)\n    alpha_tau ~ dgamma(0.001, 0.001)                       # (8)\n    beta_c ~ dnorm(0.0, 1.0e-6)                            # (9)\n    beta_tau ~ dgamma(0.001, 0.001)                        # (10)\n    \n    for i in 1:N\n        alpha[i] ~ dnorm(alpha_c, alpha_tau)               # (3)\n    end\n\n    for i in 1:N\n        beta[i] ~ dnorm(beta_c, beta_tau)                  # (4)\n    end\n\n    for i in 1:N\n        for j in 1:T\n            mu[i, j] = alpha[i] + beta[i] * (x[j] - xbar)  # (2)\n        end\n    end\n    \n    for i in 1:N\n        for j in 1:T    \n            Y[i, j] ~ dnorm(mu[i, j], tau_c)               # (1)\n        end\n    end\n    \n    alpha0 = alpha_c - xbar * beta_c                        # (11)\nend\n\nWhile all three programs define the same model, only the latter two can run sequentially (e.g., for sampling) without encountering a \"read before write\" error. These are called sequential versions because they respect data dependencies in order.\n\nWe use a statement dependence graph to analyze these dependencies. An edge exists from statement Ssource to Ssink if Ssink uses a value defined by Ssource.\n\nConsider this excerpt from the original Rats program:\n\nfor i in 1:N\n    for j in 1:T\n        Y[i, j] ~ dnorm(mu[i, j], tau_c)              # (1)\n        mu[i, j] = alpha[i] + beta[i] * (x[j] - xbar)  # (2)\n    end\nend\n\nStatement (2) defines mu[i, j], which statement (1) uses. Thus, the dependence graph contains an edge (2) -> (1). This is a flow dependence (or Read-After-Write). (We will not consider Write-After-Read and Write-After-Write dependencies.)\n\nThe full statement dependence graph for Rats is:\n\nflowchart TB\n    8 --> 3\n    7 --> 3\n    10 --> 4\n    9 --> 11\n    9 --> 4\n    7 --> 11\n    3 --> 2\n    4 --> 2\n    2 --> 1\n    5 --> 1\n    5 --> 6\n\nThis graph is acyclic. But given this dependence graph, we can only produce Version 2 of the program by fissioning all the loops. The fissioning is conservative because given the dependence edges, we can only ensure the sequential order by finishing all the computation associated with a statement before moving on to the next one.\n\nConsider this example:\n\nfor i in 1:N\n    x[i] ~ normal(0, 1)     # (1)\n    y[i] ~ normal(x[N], i)  # (2) \nend\n\nThe dependence graph is just (1) -> (2), which is acyclic. However, this loop cannot run sequentially. Statement (2) at iteration i needs x[N], but statement (1) defines x[N] only at iteration N. Any iteration i < N for statement (2) reads x[N] before it's written.\n\nThe valid sequential version requires loop fission:\n\nfor i in 1:N\n    x[i] ~ normal(0, 1)     # (1)\nend\nfor i in 1:N    \n    y[i] ~ normal(x[N], i)  # (2) \nend\n\nBut this is not totally satisfactory, because ideally we would like to tell when we don't have to fission all the loops, as in Version 1 of Rats.\n\nThis shows the statement dependence graph alone is not quite sufficient. We need to analyze dependencies within loops more precisely using iteration spaces and dependence vectors. This allows transformations like loop fission (used in Version 2 of Rats).","category":"section"},{"location":"developers/source_gen/#Iteration-Space-and-Vectors","page":"Source Code Generation","title":"Iteration Space and Vectors","text":"Consider this loop:\n\nfor i in 1:2\n    for j in 1:3\n        x[i] ~ normal(0, j)     # (1)\n        y[i] ~ normal(x[2], i)  # (2) \n    end\nend\n\nEach execution of the loop body corresponds to an iteration vector veck = (i j). The set of all possible iteration vectors is the iteration space, here (i j)  1 le i le 2 1 le j le 3. Iterations execute sequentially in lexicographical order: (1,1), (1,2), (1,3), (2,1), (2,2), (2,3).","category":"section"},{"location":"developers/source_gen/#Dependence-Vectors","page":"Source Code Generation","title":"Dependence Vectors","text":"If a statement execution at iteration veci (source) defines a value used by a statement execution at iteration vecj (sink), the dependence vector is vecd = vecj - veci. It represents the distance between dependent iterations. (Sometimes, we don't care about the distance between define and use, so we can simply use the sign of the elements of the dependence vector to represent the dependence relation.)\n\nFor sequential execution to be valid, all dependence vectors vecd must be lexicographically non-negative (vecd succeq vec0). This means either vecd = vec0 or the first non-zero element of vecd is positive.\n\nA lexicographically negative vector (vecd prec vec0) indicates a violation. It means the sink iteration vecj executes before the source iteration veci in sequential order, but vecj needs the value produced by veci.","category":"section"},{"location":"developers/source_gen/#Dependence-Vectors-and-Sequential-Execution","page":"Source Code Generation","title":"Dependence Vectors and Sequential Execution","text":"Dependence vectors help analyze loops. Consider this invalid loop:\n\nx[6] ~ Normal() # (1)\n\nfor i in 1:5\n    x[i] = x[i+1] + i # (2)  \nend\n\nStatement (2) computes x[i] using x[i+1]. The value x[i+1] is defined by statement (2) at iteration i+1 (source). It is used by statement (2) at iteration i (sink). The dependence vector is vecd = vecj_sink - veci_source = (i) - (i+1) = (-1). Since vecd prec vec0, this loop violates sequential order. Computing x[1] requires x[2], defined in a later iteration.\n\nThis loop is sequentially valid:\n\nx[1] ~ Normal() # (1)\n\nfor i in 2:5\n    x[i] = x[i-1] + i # (2)  \nend\n\nStatement (2) computes x[i] using x[i-1]. The value x[i-1] is defined by statement (2) at iteration i-1 (source). It is used by statement (2) at iteration i (sink). The dependence vector is vecd = vecj_sink - veci_source = (i) - (i-1) = (1). Since vecd succ vec0, this loop respects sequential order.","category":"section"},{"location":"developers/source_gen/#Loop-Independent-vs.-Loop-Carried-Dependencies","page":"Source Code Generation","title":"Loop-Independent vs. Loop-Carried Dependencies","text":"Dependencies involving loops are classified by their dependence vector vecd = vecj - veci:\n\nLoop-Independent Dependence: Occurs within the same iteration: vecd = vec0.\nLoop-Carried Dependence: Occurs between different iterations: vecd neq vec0.","category":"section"},{"location":"developers/source_gen/#Cyclic-Graphs:-State-Space-Models","page":"Source Code Generation","title":"Cyclic Graphs: State-Space Models","text":"The Rats example has an acyclic statement dependence graph—common for hierarchical and regression models that don't involve temporal dependencies.\n\nHowever, state-space models (SSMs) introduce cycles in the dependence graph due to recursive structures like x[t] depending on x[t-1]. These cycles are not errors; they represent valid sequential recurrences. To handle them, we use dependence vectors to verify that all loop-carried dependencies are lexicographically non-negative.\n\nConsider this Hidden Markov Model (HMM) fragment:\n\n# Main loop processing time steps 2 to T\nfor i in 2:T\n    # State transition: s[i] depends on s[i-1]\n    s[i] ~ dcat(transition[s[i-1], 1:K])  # (S1)\n    \n    # Emission model: Y[i] depends on s[i]\n    Y[i] ~ dnorm(mu[s[i]], tau[s[i]])     # (S2)\nend\n\n# Initial state at time 1\ns[1] ~ dcat(pi[1:K])                      # (S3) Prior for first state\n\nfor k in 1:K\n    # Priors for parameters\n    mu[k] ~ dnorm(0, 0.01)                # (S4) Mean for state k\n    tau[k] ~ dgamma(0.01, 0.01)           # (S5) Precision for state k\n    transition[k, 1:K] ~ ddirch(alpha[1:K]) # (S6) Transition probabilities from state k\n    pi[1:K] ~ ddirch(alpha[1:K])          # (S7) Prior for initial state distribution\nend\n\nflowchart TD\n    subgraph PriorsAndParameters\n        S4[\"(S4) mu[k] ~ dnorm\"]\n        S5[\"(S5) tau[k] ~ dgamma\"]\n        S6[\"(S6) transition[k, 1:K] ~ ddirch\"]\n        S7[\"(S7) pi[1:K] ~ ddirch\"]\n    end\n\n    subgraph InitialState\n        S3[\"(S3) s[1] ~ dcat(pi[1:K])\"]\n    end\n\n    subgraph MainLoop [for i in 1:T]\n        S1[\"(S1) s[i] ~ dcat(transition[s[i-1], 1:K])\"]\n        S2[\"(S2) Y[i] ~ dnorm(mu[s[i]], tau[s[i]])\"]\n    end\n\n    S7 --> S3\n    S6 --> S1\n    S3 --> S1\n    S1 -- loop-carried --> S1\n    S4 --> S2\n    S5 --> S2\n    S1 --> S2\n\n    %% Note: alpha is assumed to be an input/hyperparameter\n\nIn this example, there is a self loop on S1. These represent the state transition. To see that we can actually sequentially execute the program, we can compute the dependence vectors.\n\nThe computation of the dependence vectors is done in the following steps: When executing the for loop from i = 2 to i = T, we need to compute the dependence vector. Let's examine the case when i = 2:\n\nLHS: s[2] is defined at iteration i=2\nRHS: s[1] is defined at iteration i=1\nDependence vector: vecd = vecj_sink - veci_source = (2) - (1) = (1)\n\nAll subsequent iterations follow the same pattern and have the same dependence vector of (1). Because all dependence vectors are lexicographically non-negative, the loop is sequentially valid.\n\nThis requires storing the loop variable i for each variable, but we already computed this with JuliaBUGS compilation, so not much overhead is required. \n\nIt should be noted that this approach doesn't scale well for general Julia programs, but it works appropriately for BUGS since the compilation process already has a time complexity of O(N) with respect to the number of variables.","category":"section"},{"location":"developers/source_gen/#Summary","page":"Source Code Generation","title":"Summary","text":"To summarize:\n\nTo transform a BUGS program into a sequentially valid program, we will only apply two simple transformations, loop fission and statement reordering. These transformations will not need to modify loop bounds, renaming variables, adding any control flow, or make any changes to specific statements.\n\nWhether a program can be transformed is determined by the following procedure:\n\nFirst a statement dependence graph is computed.\n\nIf the statement dependence graph is acyclic, then we topologically sort the statements and fission all the loops to create a sequentially valid program.\n\nIf the statement dependence graph is cyclic, we check whether all statements in the cycle belong to the same loop nest. If so, we compute dependence vectors for the loop-carried edges. When all dependence vectors are lexicographically non-negative, the cycle represents a valid sequential recurrence (e.g., x[t] depending on x[t-1]), and we can generate correct code.\n\nIf the cycle spans multiple loop nests, or if any dependence vector is negative, the program cannot be transformed automatically and must be rewritten manually.","category":"section"},{"location":"developers/source_gen/#Implementation-Overview","page":"Source Code Generation","title":"Implementation Overview","text":"At a high level, the current implementation follows a conservative, correctness‑first pipeline. It favors simple, explainable transformations and stops with diagnostics when safety cannot be guaranteed.\n\nBuild coarse statement graph: Construct a statement‑level dependence graph from the compiled BUGS graph. Nodes are top‑level statements; edges indicate that any variable produced by one statement is used by another.\nRemove transformed data: Copy the model AST and remove statements whose variables are all compile‑time computable (in‑degree or out‑degree zero at the coarse level). This keeps the runtime program focused on values that must be evaluated.\nFully fission loops (intermediate step): Split each loop so that every statement runs in its own loop nest. This simplifies ordering by allowing per-statement reasoning. The loop nests are retained as metadata. Statements are re-grouped during reconstruction.\nClassify dependence vectors: The coarse graph has statement-level edges (e.g., statement 3 → statement 2). For each coarse edge, we find the underlying variable-level edges (e.g., alpha[1] → mu[1,1], alpha[2] → mu[2,1], etc.) and classify each by comparing loop indices:\nZero: loop-independent (same iteration)\nPositive: loop-carried, lexicographically non-negative\nNegative: lexicographically negative (unsafe for sequential order)\nUnknown: cannot be compared (e.g., different loop nests or data-dependent indexing)\nFilter into an ordering graph: Build an ordering graph for statements by:\nDropping self‑edges when all corresponding fine edges are Positive (safe loop‑carried self‑recurrence such as x[t] depends on x[t‑1]).\nRetaining all cross‑statement edges by default to preserve producer→consumer ordering.\nAborting if any Negative dependence is observed (unsafe), or recording Unknown dependences for diagnostics.\nResolve remaining cycles conservatively: If cycles remain in the ordering graph, attempt limited loop fusion within strongly‑connected components (SCCs) that meet all of the following:\nAll statements share the exact same loop nest (same variables and identical bounds).\nNo Negative or Unknown fine‑grained dependences among the SCC members.\nThe subgraph induced by Zero dependences is acyclic, providing a valid intra‑iteration order.\nIf this succeeds, expand clusters in topological order to obtain a global statement order. Otherwise, abort with diagnostics.\nReconstruct structured loops: After sorting the fissioned statements, group consecutive statements with identical loop nests and reconstruct a single nested for around a block of statements rather than emitting many tiny loops. This preserves structure while avoiding over‑fissioning in the final program.\nLower observations and flatten blocks: Insert observation guards/casts during lowering, and flatten intermediate :block nodes introduced by reconstruction so that analysis and codegen see a normalized statement sequence.\n\nDiagnostics are collected throughout and surfaced to help users rewrite programs when the transformation cannot be proven safe (e.g., negative or unknown dependences).","category":"section"},{"location":"developers/source_gen/#What-works-well-now","page":"Source Code Generation","title":"What works well now","text":"Acyclic statement graphs (e.g., hierarchical/regression models like Rats) — the common case, handled by topological sort and loop fission\nState-space patterns with self-recurrence inside a single loop nest (e.g., x[t] depends on x[t-1])\nCross-coupled SSMs where multiple state arrays reference each other at lag 1, provided they share the same time loop\nGrid SSMs with independent per-row recurrences, plus observation loops reading current state","category":"section"},{"location":"developers/source_gen/#What-we-intentionally-reject","page":"Source Code Generation","title":"What we intentionally reject","text":"Inter-loop cycles requiring fusion across different loop nests\nData-dependent indexing producing Unknown dependences\nAny pattern with Negative dependences\n\nThese require manual refactoring. See Unsupported Patterns for detailed examples.","category":"section"},{"location":"developers/source_gen/#Unsupported-Patterns","page":"Source Code Generation","title":"Unsupported Patterns","text":"Some dependency structures require transformations beyond statement reordering and loop fission. We do not attempt these transformations automatically—they are hard to implement correctly and the resulting code can be difficult to understand. Instead, we abort with diagnostics and recommend manual refactoring.","category":"section"},{"location":"developers/source_gen/#Inter-Loop-Cycles","page":"Source Code Generation","title":"Inter-Loop Cycles","text":"Consider this model,\n\nsumX[1] = x[1] # (S1)\n\n# Loop 1: for i in 2:N\nsumX[i] = sumX[i-1] + x[i] # (S2)\n# End Loop 1\n\n# Loop 2: for i in 1:N/2 (loop over even indices)\nx[2*i] ~ dnorm(sumX[2*i-1], tau) # (S3)\n# End Loop 2\n\n# Loop 3: for i in 1:N/2 (loop over odd indices)\nx[2*i + 1] ~ dgamma(sumX[2*i], tau) # (S4)\n# End Loop 3\n\nthe dependency graph is:\n\nflowchart TD\n    S_input[\"(Input) x[1]\"] --> S1[\"(S1) sumX[1] = x[1]\"]\n\n    subgraph Loop1 [for i in 2:N]\n      S2[\"(S2) sumX[i] = sumX[i-1] + x[i]\"]\n    end\n\n    subgraph Loop2 [for i in 1:N/2 - Even Indices]\n      S3[\"(S3) x[2*i] ~ dnorm(sumX[2*i-1], tau)\"]\n    end\n\n    subgraph Loop3 [for i in 1:N/2 - Odd Indices]\n      S4[\"(S4) x[2*i + 1] ~ dgamma(sumX[2*i], tau)\"]\n    end\n\n    S1 --> S2\n    S2 -- loop-carried --> S2\n\n    S1 --> S3\n    S2 -- inter-loop --> S3\n    S2 -- inter-loop --> S4\n\n    S3 -- inter-loop --> S2\n    S4 -- inter-loop --> S2\n    \n    S3 -- inter-loop --> S4\n\nThis code exhibits a complex web of dependencies: S2 (calculating sumX) depends on x values. S3 (defining even xs) depends on odd sumX values. S4 (defining odd xs) depends on even sumX values. Critically, S2 needs both even and odd x values (calculated in S3 and S4 respectively) to calculate the sumX values that S3 and S4 themselves depend on. \n\nThis creates a cyclical dependency across the three loops. To resolve this and make the code sequentially executable, a sophisticated transformation involving loop fusion and statement interleaving is required. All three loops need to be merged into a single loop structure that correctly orders the calculations within each logical iteration i (from 1 to N).\n\nA possible (conceptual) fused structure might look like this:\n\nsumX[1] = x[1] \n# Potentially handle x[2] separately depending on loop bounds/logic\nfor i = 2 to N # Or a similar loop structure covering all indices\n   if i is even:\n       # Calculate x[i] (originally S3) - needs sumX[i-1]\n       x[i] ~ dnorm(sumX[i-1], tau)\n   else: # i is odd\n       # Calculate x[i] (originally S4) - needs sumX[i-1]\n       x[i] ~ dgamma(sumX[i-1], tau) \n   \n   # Calculate sumX[i] (originally S2) - needs x[i] just calculated\n   sumX[i] = sumX[i-1] + x[i]\nend","category":"section"},{"location":"developers/source_gen/#Data-Dependent-Indexing","page":"Source Code Generation","title":"Data-Dependent Indexing","text":"When data values determine array indices, dependencies become impossible to analyze statically without unrolling. For instance,\n\nbegin\n    z[2] = f(x[1]) # (S1)\n    y[2] = g(x[3]) # (S2)\n\n    for i in 1:3\n        x[i] = y[a[i]] + z[b[i]] # (S3)\n    end\nend\n\ndata = (a = [2, 3, 1], b = [3, 1, 2])\n\nthis results in the following dependencies between model variables\n\nx[1] <- y[2], z[3]\nx[2] <- y[3], z[1]\nx[3] <- y[1], z[2]\nz[2] <- x[1]\ny[2] <- x[2]\n\nwith dependence graph\n\ngraph TD\n    y2 --> x1\n    z3 --> x1\n    z1 --> x2\n    y3 --> x2\n    y1 --> x3\n    z2 --> x3\n    x1 --> z2\n    x2 --> y2\n\nThe statement dependence graph of this program, on the other hand is (obtained by merging all the x nodes)\n\ngraph TD\n    S3 --> S1\n    S3 --> S2\n    S1 --> S3\n    S2 --> S3\n\nThis represents a worst case where we can't do much better than fully unrolling.","category":"section"},{"location":"developers/source_gen/#Lowering-BUGS-Programs-to-Log-Density-Code","page":"Source Code Generation","title":"Lowering BUGS Programs to Log-Density Code","text":"Once we have a sequentially valid program, we lower it to Julia code that computes log-densities. This involves distinguishing observations from parameters and handling mixed cases where some array elements are observed and others are not.\n\nThe reordered Version 2 of Rats becomes:\n\nquote\n    var\"beta.tau\" ~ dgamma(0.001, 0.001)\n    var\"beta.c\" ~ dnorm(0.0, 1.0e-6)\n    var\"alpha.tau\" ~ dgamma(0.001, 0.001)\n    var\"alpha.c\" ~ dnorm(0.0, 1.0e-6)\n    alpha0 = var\"alpha.c\" - xbar * var\"beta.c\"\n    var\"tau.c\" ~ dgamma(0.001, 0.001)\n    sigma = 1 / sqrt(var\"tau.c\")\n    for i = 1:30\n        beta[i] ~ dnorm(var\"beta.c\", var\"beta.tau\")\n    end\n    for i = 1:30\n        alpha[i] ~ dnorm(var\"alpha.c\", var\"alpha.tau\")\n    end\n    for i = 1:30\n        for j = 1:5\n            mu[i, j] = alpha[i] + beta[i] * (x[j] - xbar)\n        end\n    end\n    for i = 1:30\n        for j = 1:5\n            Y[i, j] \\eqsim dnorm(mu[i, j], var\"tau.c\")\n        end\n    end\nend\n\nWe made a simple change to the program to prepare for lowering: we need to distinguish between observations and model parameters (because they correspond to different code). We introduce a new operator into the program \\eqsim to indicate that the left hand side is an observation.","category":"section"},{"location":"developers/source_gen/#Handling-Mixed-Observations-and-Parameters","page":"Source Code Generation","title":"Handling Mixed Observations and Parameters","text":"BUGS supports mixing observations and model parameters for different elements of the same array variable. To support this, we introduce a guard to use conditional logic to decide what computation to do for different iteration of the same statement.\n\n@bugs begin\n    for i in 1:2\n        for j in 1:5\n            x[i, j] ~ Normal()\n        end\n    end\nend\n\ndata = (x = [1 2 missing 4 5; 1 2 missing 4 5])\n\ngenerated code:\n\nbegin\n    for i in 1:2\n        for j in 1:5\n            if i == 1 && j == 3 || i == 2 && j == 3\n                x[i, j] ~ Normal()\n            else\n                x[i, j] ≂ Normal()\n            end\n        end\n    end\nend","category":"section"},{"location":"developers/source_gen/#Handling-Mixed-Data-Transformation-and-Deterministic-Assignments","page":"Source Code Generation","title":"Handling Mixed Data Transformation and Deterministic Assignments","text":"For instance\n\nfor i in 1:5\n    x[i] = y[i] + 1\nend\n\nif the data is\n\ny = [1, 2, missing, missing, 2]\n\nthis is generally allowed in BUGS.\n\nx[1], x[2], x[5] can be computed at compile time, so these are \"transformed data\". x[3], x[4] need to be computed at evaluation time. And only x[3] and x[4] are in the compiled graph.\n\nFor generated Julia program, if a statement can be eliminated because all the variables stemmed from this statement are \"transformed data\". While in the above case, where a statements corresponds to both transformed data and deterministic variables. It will be left in the generated program as is. In this case, there will be redundant computation.","category":"section"},{"location":"developers/parser/#BUGS-Parser","page":"Parser","title":"BUGS Parser","text":"The macro @bugs produces a Julia Expr object that represents the BUGS model definition.\n\nIf the input is a String, it's assumed to be a program in the original BUGS language. In this case, the macro will first convert the program to an equivalent Julia program, then use the Julia parser to parse the program into an Expr object.\n\nBoth model definitions written in Julia and those written in the original BUGS and subsequently parsed are now represented as a Julia Expr object. These objects go through syntax checking and post-processing to create the input for the compile function.\n\nBelow, we describe how the original BUGS program is translated to an equivalent Julia program and detail the post-processing done to the Expr object.","category":"section"},{"location":"developers/parser/#BUGS-to-Julia-Translation","page":"Parser","title":"BUGS to Julia Translation","text":"In this section, we refer to the translation program as the \"parser\" and the translating process as \"parsing\". Although the parser doesn't produce a syntax tree, it does follow the form of a recursive descent parser, building a Julia program in the form of a vector of tokens rather than a syntax tree.\n\nThis general implementation is heavily inspired by JuliaSyntax.jl, the official parser for Julia since version 1.10.\n\nThe BUGS parser implemented here takes a token stream with a recursive descent structure and checks the program's correctness. Here's how it works:\n\nUse tokenize to obtain the token vector.\nInspect the tokens and build the Julia version of the program as a vector of tokens.\nPush the token to the Julia version of the program vector when appropriate.\nDetect errors and make necessary alterations to tokens, such as deletion, combination, or replacement.\n\nDuring the recursive descent, BUGS syntax tokens will be translated into Julia syntax tokens. Some tokens will remain as they are, while others will be transformed, removed, or new tokens may be added.\n\nThe parser will throw an error if it encounters a program that does not adhere to strict BUGS syntax.","category":"section"},{"location":"developers/parser/#Some-Notes-on-Error-Recovery","page":"Parser","title":"Some Notes on Error Recovery","text":"The current error recovery is ad hoc and primarily rudimentary. If the program is correct, it will produce the correct result. If the program is syntactically or semantically incorrect, the token stream will not be pushed forward, resulting in failure.\n\nThe failure detection mechanism checks if two errors occur with the same \"current token\". If they do, the parser stops and reports the error. This ensures that the parser won't incorrectly parse a flawed program.","category":"section"},{"location":"inference/auto_marginalization/#Automatic-Marginalization-in-Mixed-Discrete-Continuous-Models","page":"Auto-Marginalization","title":"Automatic Marginalization in Mixed Discrete-Continuous Models","text":"","category":"section"},{"location":"inference/auto_marginalization/#The-Problem","page":"Auto-Marginalization","title":"The Problem","text":"Modern gradient-based inference methods require differentiable log-densities:\n\nHMC, NUTS, variational inference need smooth objectives \nDiscrete variables aren't differentiable\nSolution: marginalize out discrete variables exactly \n\nChallenge: How to do this efficiently?","category":"section"},{"location":"inference/auto_marginalization/#Example-Model","page":"Auto-Marginalization","title":"Example Model","text":"Mixed BN: discrete XCZ; continuous AB; observed D.\n\ngraph LR\n    X((X)):::discrete --> A((A)):::continuous\n    A --> B((B)):::continuous\n    A --> C((C)):::discrete\n    B --> D((D)):::observed\n    C --> D\n    Z((Z)):::discrete --> D\n\n    classDef discrete fill:#FFF4E6,stroke:#D9480F,stroke-width:2px,stroke-dasharray:5\n    classDef continuous fill:#E7F5FF,stroke:#1C7ED6,stroke-width:2px\n    classDef observed fill:#E6FCF5,stroke:#2B8A3E,stroke-width:2px","category":"section"},{"location":"inference/auto_marginalization/#BUGS-Program","page":"Auto-Marginalization","title":"BUGS Program","text":"model {\n  # Discrete priors\n  X ~ dcat(piX[])  # piX is length-|X|\n  Z ~ dcat(piZ[])  # piZ is length-|Z|\n\n  # Conditionals\n  A ~ dnorm(muX[X], 1/pow(sigmaA,2))\n  B ~ dnorm(A, 1/pow(sigmaB,2))\n\n  # Logistic gate for C\n  logit(pC) <- alpha0 + alpha1 * A\n  pCvec[1] <- 1 - pC\n  pCvec[2] <- pC\n  C ~ dcat(pCvec[])\n\n  # Likelihood\n  D ~ dnorm(B + deltaC[C] + deltaZ[Z], 1/pow(sigmaD,2))\n}","category":"section"},{"location":"inference/auto_marginalization/#Joint-Probability","page":"Auto-Marginalization","title":"Joint Probability","text":"Following topological order z x a b c d:\n\n$\n\n\\begin{aligned} \\log p(z, x, a, b, c, d) &= \\log p(z) + \\log p(x) + \\log p(a \\mid x) \\\n&\\quad + \\log p(b \\mid a) + \\log p(c \\mid a) \\\n&\\quad + \\log p(d \\mid b, c, z) \\end{aligned} $","category":"section"},{"location":"inference/auto_marginalization/#Marginalization-Target","page":"Auto-Marginalization","title":"Marginalization Target","text":"For gradient-based inference, marginalize out discrete variables:\n\n$\n\n\\begin{aligned} \\log p(a, b, d) = \\log &\\sum{z \\in \\mathcal{Z}} \\sum{x \\in \\mathcal{X}} \\Big[ p(z) \\cdot p(x) \\cdot p(a \\mid x) \\cdot p(b \\mid a) \\\n&\\cdot \\sum_{c \\in \\mathcal{C}} p(c \\mid a) \\cdot p(d \\mid b, c, z) \\Big] \\end{aligned} $\n\nfollowing the same topological order in the computation.","category":"section"},{"location":"inference/auto_marginalization/#Naive-Enumeration","page":"Auto-Marginalization","title":"Naive Enumeration","text":"Full expansion reveals massive redundancy:\n\n$\n\n\\begin{aligned} &p(z{=}1) \\cdot p(x{=}1) \\cdot p(a|x{=}1) \\cdot p(b|a) \\cdot p(c{=}1|a) \\cdot p(d|b,c{=}1,z{=}1) \\\n&p(z{=}1) \\cdot p(x{=}1) \\cdot p(a|x{=}1) \\cdot p(b|a) \\cdot p(c{=}2|a) \\cdot p(d|b,c{=}2,z{=}1) \\\n&p(z{=}1) \\cdot p(x{=}2) \\cdot p(a|x{=}2) \\cdot p(b|a) \\cdot p(c{=}1|a) \\cdot p(d|b,c{=}1,z{=}1) \\\n&p(z{=}1) \\cdot p(x{=}2) \\cdot p(a|x{=}2) \\cdot p(b|a) \\cdot p(c{=}2|a) \\cdot p(d|b,c{=}2,z{=}1) \\\n&\\vdots \\text{ (4 more terms for } z{=}2) \\end{aligned} $","category":"section"},{"location":"inference/auto_marginalization/#Identifying-Redundancy","page":"Auto-Marginalization","title":"Identifying Redundancy","text":"Looking at the 8 terms, each subexpression appears multiple times:\n\np(dbc=1z=1)\ncomputed twice (for x=1 and x=2)\np(dbc=2z=1)\ncomputed twice\np(dbc=1z=2)\ncomputed twice\np(dbc=2z=2)\ncomputed twice\n\nLarger suffixes also repeat:\n\np(ba) cdot p(c=1a) cdot p(dbc=1z=1)\nappears for both x=1 and x=2\n...","category":"section"},{"location":"inference/auto_marginalization/#The-Solution:-Strategic-Caching","page":"Auto-Marginalization","title":"The Solution: Strategic Caching","text":"Cache intermediate results to avoid recomputation.\n\nKey challenge: What to use as cache key?\n\nNaive approach: Use all discrete variables seen so far\n\nDoesn't work, because it is equivalent to enumeration\n\nSolution: Use the minimal set of discrete latent that still affect the future","category":"section"},{"location":"inference/auto_marginalization/#The-Frontier-Concept","page":"Auto-Marginalization","title":"The Frontier Concept","text":"K_k\n\nis the minimal already-visited set whose values appear in any unvisited factor; equivalently, the separator induced by your order at step k.\n\nThis separates past computations from future ones.\n\nTraditional Bayesian network inference exploits conditional independence. We achieve the same effect through runtime caching based on the frontier.","category":"section"},{"location":"inference/auto_marginalization/#Frontier-Evolution","page":"Auto-Marginalization","title":"Frontier Evolution","text":"Position Discrete frontier K_k cap Q Why it remains needed\nStart  Nothing visited yet.\nAfter z z z rightarrow d is still ahead; future depends on z.\nAfter x z x z rightarrow d remains; x still influences future through a.\nAfter c z c Both z and c feed d ahead; x no longer affects future.","category":"section"},{"location":"inference/auto_marginalization/#Impact-of-Order","page":"Auto-Marginalization","title":"Impact of Order","text":"Moving Z late (xabczd) delays introducing z into the frontier, shrinking early cache keys.\n\nPlacing B before branching on C avoids recomputing p(bmid a) for each (cz).","category":"section"},{"location":"inference/auto_marginalization/#Algorithm-Overview","page":"Auto-Marginalization","title":"Algorithm Overview","text":"Evaluate in a topological order. Enumerate at discrete sites. Memoize each suffix with key (k K_kcap Q).","category":"section"},{"location":"inference/auto_marginalization/#Precomputing-Frontier-Keys","page":"Auto-Marginalization","title":"Precomputing Frontier Keys","text":"One backward pass computes all frontiers.\n\nP ← ∅                          // parents of future nodes\nfor k = n down to 1:           // process v_n, …, v_1\n    K_k ← P ∩ {v_1,…,v_k}      // frontier after v_k\n    P  ← P ∪ parents(v_k)\n\nCache key at discrete sites = K_k cap textdiscrete variables","category":"section"},{"location":"inference/auto_marginalization/#Example-with-order-z,-x,-a,-b,-c,-d","page":"Auto-Marginalization","title":"Example with order z x a b c d","text":"Edges: x to a, a to b, a to c, b to d, c to d, z to d\n\nPosition P (parents-of-future) Frontier K_k Cache key (discrete only)\nAfter d   -\nAfter c b c z z b c z c\nAfter b z a b c z a b (no cache)\nAfter a z a b c z a (no cache)\nAfter x z a b c x z x z x\nAfter z z a b c x z z","category":"section"},{"location":"inference/auto_marginalization/#Factor-Graph-Representation","page":"Auto-Marginalization","title":"Factor Graph Representation","text":"Marginalization can also be formulated using message passing on factor graphs.\n\ngraph TD\n    X((X)):::discrete\n    Z((Z)):::discrete\n    C((C)):::discrete\n    A{A=a}:::clamped\n    B{B=b}:::clamped\n    D((D=d)):::observed\n\n    fX[p_x]:::factor\n    fZ[p_z]:::factor\n    fA[p_ax]:::factor\n    fB[p_ba]:::factor\n    fC[p_ca]:::factor\n    fD[p_dbcz]:::factor\n\n    A --- fA\n    A --- fB\n    A --- fC\n    B --- fB\n    B --- fD\n    C --- fC\n    C --- fD\n    D --- fD\n    X --- fX\n    X --- fA\n    Z --- fZ\n    Z --- fD\n\n    classDef discrete fill:#FFF4E6,stroke:#D9480F,stroke-width:2px,stroke-dasharray:5\n    classDef clamped fill:#B0D4F1,stroke:#1C7ED6,stroke-width:3px\n    classDef observed fill:#C3F0DC,stroke:#2B8A3E,stroke-width:3px\n    classDef factor fill:#F1F3F5,stroke:#495057,stroke-width:2px","category":"section"},{"location":"inference/auto_marginalization/#Message-Passing-with-Elimination-Order:-X,-then-(C,Z)","page":"Auto-Marginalization","title":"Message Passing with Elimination Order: X, then (CZ)","text":"We choose B as our target node where all messages flow toward.\n\nWhy this order? After conditioning on (ABD), the graph forms a tree where:\n\nX\nis isolated upstream of A\nC\nand Z converge at D but are independent given clamped values\n\nTo compute the belief at B, we collect all information flowing toward it:\n\nStep 1: Upstream message (from X through A to B) $ \\phiX(a) = \\sum{x} p(x)\\,p(a|x) $ This eliminates X and will flow to B via the factor p(ba).\n\nAfter eliminating X, we have:\n\ngraph TD\n    Z((Z)):::discrete\n    C((C)):::discrete\n    A{A=a}:::clamped\n    B{B=b}:::clamped\n    D((D=d)):::observed\n\n    phiX[φ_X]:::newfactor\n    fZ[p_z]:::factor\n    fB[p_ba]:::factor\n    fC[p_ca]:::factor\n    fD[p_dbcz]:::factor\n\n    A --- phiX\n    A --- fB\n    A --- fC\n    B --- fB\n    B --- fD\n    C --- fC\n    C --- fD\n    Z --- fZ\n    Z --- fD\n    D --- fD\n\n    classDef discrete fill:#FFF4E6,stroke:#D9480F,stroke-width:2px,stroke-dasharray:5\n    classDef clamped fill:#B0D4F1,stroke:#1C7ED6,stroke-width:3px\n    classDef observed fill:#C3F0DC,stroke:#2B8A3E,stroke-width:3px\n    classDef factor fill:#D8D8D8,stroke:#495057,stroke-width:2px\n    classDef newfactor fill:#FFE3E3,stroke:#C92A2A,stroke-width:2px\n\nStep 2: Downstream message (from D back to B)\n\nTo compute what D tells us about B, we eliminate C and Z:\n\nC\nbrings information p(ca) from its connection to A\nZ\nbrings its prior p(z)\nBoth connect to B through factor p(dbcz)\n\nThe combined message to B: $ \\phi{CZ}(b) = \\sum{c,z} p(c\\mid a)\\,p(z)\\,p(d\\mid b,c,z) $","category":"section"},{"location":"inference/auto_marginalization/#Final-Marginal-Likelihood","page":"Auto-Marginalization","title":"Final Marginal Likelihood","text":"At node B, we combine:\n\nUpstream message: phi_X(a) through factor p(ba)\nLocal factor: p(ba)\nDownstream message: phi_CZ(b) from the D branch\n\nThe unnormalized belief at B:\n\n$\n\n\\boxed{\\; p(a,b,d) = \\phiX(a) \\cdot p(b\\mid a) \\cdot \\phi{CZ}(b) \\;} $\n\nExpanding each message: $ \\begin{aligned} p(a,b,d) &= \\underbrace{\\left[\\sumx p(x)p(a|x)\\right]}{\\phiX(a)} \\cdot p(b|a) \\cdot \\underbrace{\\left[\\sum{c,z} p(c|a)p(z)p(d|b,c,z)\\right]}{\\phi{CZ}(b)}\\\n&= \\left[\\sumx p(x)p(a|x)\\right] \\cdot p(b|a) \\cdot \\left[\\sumc p(c|a) \\sum_z p(z)p(d|b,c,z)\\right] \\end{aligned} $","category":"section"},{"location":"inference/auto_marginalization/#Which-Topological-Orders-Yield-This-Factorization?","page":"Auto-Marginalization","title":"Which Topological Orders Yield This Factorization?","text":"X A B C Z D\n\non the Bayesian Network\n\nProduce: $ \\left[\\sumx p(x)p(a|x)\\right] \\cdot p(b|a) \\cdot \\left[\\sumc p(c|a) \\sum_z p(z)p(d|b,c,z)\\right] $","category":"section"},{"location":"inference/auto_marginalization/#Frontier-Evolution-for-Order-X,-A,-B,-C,-Z,-D","page":"Auto-Marginalization","title":"Frontier Evolution for Order X A B C Z D","text":"Position Discrete frontier What happens\nStart  Nothing processed yet\nAfter X  X eliminated immediately\nAfter A  A is continuous\nAfter B  B is continuous\nAfter C C C enters frontier, needed for D\nAfter Z CZ Both needed for D\nAfter D  Everything processed","category":"section"},{"location":"inference/auto_marginalization/#Messages-ARE-the-DP-Cache-Entries","page":"Auto-Marginalization","title":"Messages ARE the DP Cache Entries","text":"Message passing computes the same values as DP enumeration\n\nIn DP enumeration with caching:\n\nWe cache partial sums with key = discrete frontier\nFrontier tells us which discrete variables affect future computation\n\nIn message passing:\n\nMessages ARE these cached partial sums\nMessage indexing matches the frontier\n\nExample from our graph:\n\nComputation What it is Frontier (cache key) Reuse pattern\nsum_x p(x)p(a mid x) Message eliminating X  Computed once\nsum_z p(z)p(d mid bcz) Partial message eliminating Z C One per c value\n\nThe frontier-based cache key ensures we recompute only when necessary","category":"section"},{"location":"inference/auto_marginalization/#Two-Perspectives-on-the-Same-Algorithm","page":"Auto-Marginalization","title":"Two Perspectives on the Same Algorithm","text":"","category":"section"},{"location":"inference/auto_marginalization/#Top-down-with-memoization-(our-frontier-caching):","page":"Auto-Marginalization","title":"Top-down with memoization (our frontier caching):","text":"Start from the goal: compute p(abd)\nRecursively evaluate the DAG following topological order\nMemoize (cache) partial sums at discrete variables\nCache key = discrete frontier (what future computation needs)\nLike recursive Fibonacci with memoization","category":"section"},{"location":"inference/auto_marginalization/#Bottom-up-tabulation-(factor-graph-message-passing):","page":"Auto-Marginalization","title":"Bottom-up tabulation (factor graph message passing):","text":"Start from the leaves of the tree\nBuild up messages from smaller to larger scopes\nPrecompute all messages in optimal order\nStore messages indexed by their variables\nLike iterative Fibonacci filling a table","category":"section"},{"location":"inference/auto_marginalization/#Analogy:-Two-Ways-to-Compute-Fibonacci","page":"Auto-Marginalization","title":"Analogy: Two Ways to Compute Fibonacci","text":"Top-down with memoization:\n\nmemo = Dict()\nfunction fib_memo(n)\n    n ∈ keys(memo) && return memo[n]  # check cache\n    n ≤ 1 && return n\n    memo[n] = fib_memo(n-1) + fib_memo(n-2)  # cache result\n    return memo[n]\nend\n\nBottom-up tabulation:\n\nfunction fib_table(n)\n    dp = zeros(n+1)\n    dp[1] = 0; dp[2] = 1\n    for i in 3:n+1\n        dp[i] = dp[i-1] + dp[i-2]  # fill table\n    end\n    return dp[n+1]\nend\n\n\n\nUltimately, the caching algorithm gives factor-graph quality marginalization with the DAG representation, which has some benefits:\n\nDAG + topological order -> straight-line program\ndeterministic node gives easy-to-reason computation reuse\nIt's a natural compilation target, the evaluator is straightforward to write and understand\n\nThe contribution is to show what the cache key is and how to precompute\n\n","category":"section"},{"location":"inference/auto_marginalization/#Usage","page":"Auto-Marginalization","title":"Usage","text":"Enable auto-marginalization on a compiled model:\n\nmodel = settrans(model, true)\nmodel = set_evaluation_mode(model, UseAutoMarginalization())\n\nRequires transformed space. Discrete variables must have finite support (Categorical, Bernoulli, etc.).\n\nSee Evaluation Modes for more on set_evaluation_mode.","category":"section"},{"location":"guides/differences/#Differences-From-Other-BUGS-Implementations","page":"Differences from Other BUGS","title":"Differences From Other BUGS Implementations","text":"There exist many implementations of BUGS, notably WinBUGS, OpenBUGS, MultiBUGS, JAGS, and nimble.\n\nThis section aims to outline some differences between JuliaBUGS and other BUGS implementations. This comparison is not exhaustive, and we welcome any further discussion and reports on the matter.","category":"section"},{"location":"guides/differences/#Use-of-generic-function-in-distribution-functions","page":"Differences from Other BUGS","title":"Use of generic function in distribution functions","text":"In WinBUGS, OpenBUGS, and MultiBUGS, the arguments to distribution functions are typically restricted to variables or constants, not general expressions. JuliaBUGS, however, allows for more flexibility in these arguments.\n\nFor example, the following expressions are allowed in all BUGS implementations, including JuliaBUGS (assuming y = [1, 2, 3]):\n\nmodel {\n x ~ dnorm(y[y[2]], 1)\n}\n\nmodel {\n  x ~ dnorm(y[y[2]+1], 1)\n}\n\nHowever, JuliaBUGS allows more flexibility in these arguments. The following expressions, which are not allowed in traditional BUGS implementations, are permitted in JuliaBUGS:\n\nmodel {\n x ~ dnorm(y[1] + 1, 1)\n}\n\nmodel {\n x ~ dnorm(sum(y[1:2]), 1)\n}\n\nmodel {\n x ~ dnorm(y[sum(y[1:2])], 1)\n}","category":"section"},{"location":"guides/differences/#cumulative,-density,-and-deviance-Functions","page":"Differences from Other BUGS","title":"cumulative, density, and deviance Functions","text":"In OpenBUGS, there are several functions for working with distributions:\n\ncumulative(s1, s2): Computes the tail area (cumulative distribution function) of the distribution of s1 up to the value of s2. s1 must be a stochastic node, and s1 and s2 can be the same.\ndensity(s1, s2): Computes the density function of the distribution of s1 at the value of s2. s1 must be a stochastic node supplied as data, and s1 and s2 can be the same.\ndeviance(s1, s2): Computes the deviance of the distribution of s1 at the value of s2. s1 must be a stochastic node supplied as data, and s1 and s2 can be the same.\n\nIn MultiBUGS, these functions have been replaced with the cdf.dist, pdf.dist, and dev.dist family of functions.\n\nIn JuliaBUGS, we don't have these functions directly, but similar functionality can be achieved using the Distributions.jl package:\n\nThe cdf function computes the cumulative distribution function of a given univariate distribution at a specified value.\nThe pdf function computes the probability density function of a given univariate distribution at a specified value.\nJuliaBUGS does not currently support a deviance function equivalent to the one in OpenBUGS.","category":"section"},{"location":"guides/differences/#Example","page":"Differences from Other BUGS","title":"Example","text":"The cdf and pdf functions from the Distributions.jl are simple to use: the first argument is the distribution, and the second argument is the value at which to evaluate the function.\n\nAn OpenBUGS program like\n\nmodel {\n    x ~ dnorm(0, 1)\n    cumulative.x = cumulative(x, x)\n}\n\nwill need to be rewritten to:\n\n@bugs begin\n    x ~ Normal(0, 1)\n    cumulative_x = cdf(Normal(0, 1), x)\nend","category":"section"},{"location":"guides/differences/#Use-:-for-slicing-when-using-Julia-Syntax","page":"Differences from Other BUGS","title":"Use : for slicing when using Julia Syntax","text":"In the original BUGS language, slicing is performed using syntax like x[, ], which selects all elements from both the first and second dimensions.\n\nThe @bugs macro will automatically insert a : when given x[], however, Julia parser will throw an error if it encounters x[, ], so when using the @bugs macro in JuliaBUGS, users must explicitly use the Colon (:) operator for slicing. For example, to select all elements from both dimensions of an array x, you would write x[:, :].","category":"section"},{"location":"guides/differences/#Link-functions","page":"Differences from Other BUGS","title":"Link functions","text":"BUGS supports four link functions: log, logit, cloglog, and probit. These functions are used to support Generalized Linear Models and, in some cases, to transform random variables with constrained support to the real line.\n\nFor instance, the Seeds example features logistic regression, and the model definition is\n\nmodel\n{\n    for( i in 1 : N ) {\n        r[i] ~ dbin(p[i],n[i])\n        beta[i] ~ dnorm(0.0,tau)\n        logit(p[i]) <- alpha0 + alpha1 * x1[i] + alpha2 * x2[i] + alpha12 * x1[i] * x2[i] + beta[i]\n    }\n    alpha0 ~ dnorm(0.0,1.0E-6)\n    alpha1 ~ dnorm(0.0,1.0E-6)\n    alpha2 ~ dnorm(0.0,1.0E-6)\n    alpha12 ~ dnorm(0.0,1.0E-6)\n    sigma ~ dunif(0,10)\n    tau <- 1 / pow(sigma, 2)\n}\n\nJuliaBUGS inherits these functions, but it's important to note that the link function syntax is not supported when using the Julia-like syntax. The reason for this is that Julia uses the syntax f(...) = ... to define functions, and the link function syntax can be confusing in the Julia context.\n\nInstead, users are advised to use the inverse functions of these link functions by calling them on the right-hand side (RHS) of the statement. The inverse functions are:\n\nlog → exp\nlogit → logistic\ncloglog → cloglog\nprobit → probit\n\nSo the above model should be rewritten as\n\n@bugs begin\n    for i in 1:N\n        r[i] ~ dbin(p[i], n[i])\n        b[i] ~ dnorm(0.0, tau)\n        p[i] = logistic(alpha0 + alpha1 * x1[i] + alpha2 * x2[i] + alpha12 * x1[i] * x2[i] + b[i])\n    end\n    alpha0 ~ dnorm(0.0, 1.0e-6)\n    alpha1 ~ dnorm(0.0, 1.0e-6)\n    alpha2 ~ dnorm(0.0, 1.0e-6)\n    alpha12 ~ dnorm(0.0, 1.0e-6)\n    tau ~ dgamma(0.001, 0.001)\n    sigma = 1 / sqrt(tau)\nend\n\n(When the program is in the original BUGS syntax, the link function syntax is supported.)\n\nIt's also worth noting that JuliaBUGS uses Bijectors.jl to handle constrained parameters.","category":"section"},{"location":"guides/differences/#Compare-with-nimble","page":"Differences from Other BUGS","title":"Compare with nimble","text":"In the BUGS language, link functions are only supported in logical assignments. However, nimble extends this functionality by allowing link functions to be used in stochastic assignments as well. nimble will creates new node as intermediate variables. JuliaBUGS doesn't currently support this syntax.","category":"section"},{"location":"of_design_doc/#Design-Document:-of-Type-System-for-JuliaBUGS","page":"of Type System","title":"Design Document: of Type System for JuliaBUGS","text":"","category":"section"},{"location":"of_design_doc/#Overview","page":"of Type System","title":"Overview","text":"The of type system provides a declarative way to specify parameter types for probabilistic programming. It serves as a lightweight type annotation system that:\n\nReturns actual Julia types (not instances) that can be used in type annotations\nEncodes specifications (dimensions, bounds) in type parameters\nProvides utilities for parameter manipulation","category":"section"},{"location":"of_design_doc/#Core-Concepts","page":"of Type System","title":"Core Concepts","text":"","category":"section"},{"location":"of_design_doc/#1.-Type-Based-Design","page":"of Type System","title":"1. Type-Based Design","text":"The of function returns types with specifications encoded in type parameters:\n\nof(Array, dims...) → OfArray{Float64, N, (dim1, dim2, ...)} - Arrays with specified dimensions\nof(Array, T, dims...) → OfArray{T, N, (dim1, dim2, ...)} - Typed arrays\nof(Float64) → OfReal{Float64, Nothing, Nothing} - Unbounded 64-bit floating point numbers\nof(Float32) → OfReal{Float32, Nothing, Nothing} - Unbounded 32-bit floating point numbers\nof(Float64, lower, upper) → OfReal{Float64, lower, upper} - Bounded 64-bit floats\nof(Float32, lower, upper) → OfReal{Float32, lower, upper} - Bounded 32-bit floats\nof(Real) → OfReal{Float64, Nothing, Nothing} - Unbounded real numbers (defaults to Float64 for backward compatibility)\nof(Real, lower, upper) → OfReal{Float64, lower, upper} - Bounded real numbers (defaults to Float64)\nof(Int) → OfInt{Nothing, Nothing} - Unbounded integers\nof(Int, lower, upper) → OfInt{lower, upper} - Bounded integers\n@of(field1=..., field2=...) → OfNamedTuple{(:field1, :field2), Tuple{Type1, Type2}} - Named tuples (use @of macro only)\nof(...; constant=true) → OfConstantWrapper{T} - Marks a type as constant/hyperparameter (supported for float types and Int)","category":"section"},{"location":"of_design_doc/#2.-Type-Parameter-Encoding","page":"of Type System","title":"2. Type Parameter Encoding","text":"The system encodes extra useful information into type parameters:\n\nDimensions: Stored as tuple type parameters (e.g., (3, 4) for a 3×4 matrix)\nBounds: Numeric literals stored directly as type parameters (e.g., 0.0, 1.0), or Nothing for unbounded\nSymbolic references: Encoded using SymbolicRef{:symbol} for referencing other fields\nArithmetic expressions: Encoded using SymbolicExpr{expr} for expressions like n+1, 2*n, etc. Division operations must result in integers for array dimensions.\nField names: Stored as tuple of symbols in OfNamedTuple\nElement types: Preserved as type parameters for arrays and nested structures","category":"section"},{"location":"of_design_doc/#3.-Operations-on-Types","page":"of Type System","title":"3. Operations on Types","text":"T(;kwargs...) where T<:OfType - Create instances with specified constants (returns values, not types). Uses zero() as default for missing values.\nT(default_value; kwargs...) where T<:OfType - Create instances with specified constants, and initialise all element values to default_value, e.g. T(missing; kwargs...) initialise all element values to missing. T(...) returns instances, not types.\nof(T; kwargs...) where T<:OfType - Create concrete types by resolving constants\nrand(T::Type{<:OfType}) - Generate random values matching the type specification\nzero(T::Type{<:OfType}) - Generate zero/default values \nsize(T::Type{<:OfType}) - Get dimensions/shape of the type\nlength(T::Type{<:OfType}) - Get total number of elements when flattened\nflatten(T::Type{<:OfType}, values) - Convert structured values to flat vector\nunflatten(T::Type{<:OfType}, vec) - Reconstruct structured values from flat vector\nunflatten(T::Type{<:OfType}, missing) - Create instances where element values are initialised to missing. ","category":"section"},{"location":"of_design_doc/#4.-The-@of-Macro","page":"of Type System","title":"4. The @of Macro","text":"The @of macro provides cleaner syntax by automatically converting field references to symbols:\n\nT = @of(\n    n = of(Int; constant=true),\n    data = of(Array, n, 2)  # 'n' is automatically converted to :n\n)","category":"section"},{"location":"of_design_doc/#5.-Symbolic-Dimensions-and-Bounds","page":"of Type System","title":"5. Symbolic Dimensions and Bounds","text":"For cases where dimensions need to be specified at runtime:\n\n# Define type with symbolic dimensions using @of macro\nMatrixType = @of(\n    rows=of(Int; constant=true),\n    cols=of(Int; constant=true),\n    data=of(Array, rows, cols),\n)\n\n# Create concrete type by resolving constants\nConcreteType = of(MatrixType; rows=3, cols=4)\n# ConcreteType is @of(data=of(Array, 3, 4))\n\n# Use concrete type with rand and zero\nrand(ConcreteType)  # generates random 3×4 matrix wrapped in NamedTuple\nzero(ConcreteType)  # generates zero 3×4 matrix wrapped in NamedTuple\n\n# Partial concretization (semiconcretized)\nSemiConcreteType = of(MatrixType; rows=3)\n# SemiConcreteType is @of(cols=of(Int; constant=true), data=of(Array, 3, :cols))\n\n# Create instance by providing all constants (default to zero for data)\ninstance = MatrixType(;rows=3, cols=4)  \n# instance = (data = zeros(3, 4),)\n\n# Create instance with missing values\ninstance = MatrixType(missing; rows=3, cols=4)  \n# instance = (data = (3x4 matrix of `missing`s),)\n\n# Create instance with specific data\ninstance = MatrixType(;rows=3, cols=4, data=rand(3, 4))  \n# instance = (data = <provided 3x4 matrix>,)\n\n# Create concrete type for flatten/unflatten\nflat = flatten(ConcreteType, instance)\nreconstructed = unflatten(ConcreteType, flat)\n\n# rand and zero with concrete types\nrand(of(MatrixType; rows=3, cols=4))  # generates random instance\nzero(of(MatrixType; rows=10, cols=5)) # generates zero instance\n\n# Missing constants will error\nMatrixType(; rows=3) # Error: Constant `cols` is required but not provided\nrand(MatrixType) # Error: Cannot generate random values for types with symbolic dimensions\n\nExpandedMatrixType = @of(\n    n=of(Int; constant=true),\n    original=of(Array, n, n),\n    padded=of(Array, n+1, n+1),\n    doubled=of(Array, 2*n, n),\n    halved=of(Array, n/2, n),\n)\n\n# Create instance - all non-constant fields default to zero\ninstance = ExpandedMatrixType(; n=10)\n# This creates an instance with:\n# - original: 10×10 zero matrix\n# - padded: 11×11 zero matrix\n# - doubled: 20×10 zero matrix  \n# - halved: 5×10 zero matrix  (n/2 must result in an integer, error if not)\n\n# Create instance with custom default value\ninstance = ExpandedMatrixType(1.0; n=10)\n# This creates an instance with all matrices filled with 1.0\n\n# Generate random instance\nrand(of(ExpandedMatrixType; n=10))","category":"section"},{"location":"of_design_doc/#Example-Usage","page":"of Type System","title":"Example Usage","text":"","category":"section"},{"location":"of_design_doc/#Static-Model-Specification","page":"of Type System","title":"Static Model Specification","text":"ParamsType = @of(\n    mu0=of(Float64),\n    beta=of(Array, Float64, 3),\n    tau2=of(Float64, 0, nothing),\n    sigma2=of(Float64, 0, nothing),\n    school_effects=of(Array, 10),\n    y=of(Array, Float32, 100),\n)\n\n@model function school_model(\n    (; mu0, beta, tau2, sigma2, school_effects, y)::ParamsType,\n    X,\n    school_id,\n    n_students,\n)\n    # Priors\n    mu0 ~ Normal(0, 100)\n    beta ~ MvNormal(zeros(3), 100 * I)\n    tau2 ~ InverseGamma(0.001, 0.001)\n    sigma2 ~ InverseGamma(0.001, 0.001)\n\n    # Random effects\n    for j in 1:10\n        school_effects[j] ~ Normal(mu0, sqrt(tau2))\n    end\n\n    # Likelihood\n    for i in 1:n_students\n        j = school_id[i]\n        mean_i = school_effects[j] + dot(X[i, :], beta)\n        y[i] ~ Normal(mean_i, sqrt(sigma2))\n    end\nend","category":"section"},{"location":"of_design_doc/#Model-with-Variable-Dimensions","page":"of Type System","title":"Model with Variable Dimensions","text":"","category":"section"},{"location":"of_design_doc/#Mixture-Model","page":"of Type System","title":"Mixture Model","text":"# Mixture model where the number of mixture components is itself a parameter\nTparams = @of(\n    n_components=of(Int, 1, 3; constant=true),  # Can be 1, 2, or 3\n    weights=of(Array, n_components),            # Size depends on n_components\n    means=of(Array, n_components),              # Size depends on n_components\n    y=of(Array, 100)                            # Observations\n)\n\n@model function dynamic_mixture((; weights, means, y)::Tparams, n_components, n_obs)\n    # Prior on component probabilities (Dirichlet)\n    if n_components == 1\n        weights[1] = 1.0  # Single component has weight 1\n        means[1] ~ Normal(0.0, 1.0)\n        for i in 1:n_obs\n            y[i] ~ Normal(means[1], 0.5)\n        end\n    elseif n_components == 2\n        # Two components\n        weights ~ Dirichlet([1.0, 1.0])\n        means[1] ~ Normal(-1.0, 1.0)\n        means[2] ~ Normal(1.0, 1.0)\n        # Mixture likelihood\n        for i in 1:n_obs\n            z ~ Categorical(weights)\n            y[i] ~ Normal(means[z], 0.5)\n        end\n    else  # n_components == 3\n        # Three components\n        weights ~ Dirichlet([1.0, 1.0, 1.0])\n        means[1] ~ Normal(-2.0, 1.0)\n        means[2] ~ Normal(0.0, 1.0)\n        means[3] ~ Normal(2.0, 1.0)\n        # Mixture likelihood\n        for i in 1:n_obs\n            z ~ Categorical(weights)\n            y[i] ~ Normal(means[z], 0.5)\n        end\n    end\nend","category":"section"},{"location":"of_design_doc/#Variable-order-autoregressive-model","page":"of Type System","title":"Variable-order autoregressive model","text":"ARParams = @of(\n    order=of(Int, 1, 5; constant=true),  # AR order between 1 and 5\n    coeffs=of(Array, order),             # AR coefficients\n    sigma=of(Real, 0, nothing),          # Error variance\n    y=of(Array, 100),                    # Time series data\n)\n\n@model function variable_order_ar((; order, coeffs, sigma, y)::ARParams, n_obs)\n    # Priors\n    for i in 1:order\n        coeffs[i] ~ Normal(0.0, 0.5)  # Shrinkage prior on AR coefficients\n    end\n    sigma ~ InverseGamma(2.0, 1.0)\n    \n    # AR likelihood\n    for t in (order+1):n_obs\n        # Compute AR prediction\n        pred = 0.0\n        for i in 1:order\n            pred += coeffs[order+1-i] * y[t-i]\n        end\n        y[t] ~ Normal(pred, sqrt(sigma))\n    end\nend\n\n# Usage example\n# Create instance with specific order\nparams = ARParams(; order=3)\n# This creates an instance where coeffs has size 3, defaulting to zeros\n\n# Or with specific values\nparams = ARParams(; order=3, coeffs=[0.5, -0.3, 0.1], sigma=0.25, y=randn(100))","category":"section"},{"location":"of_design_doc/#Bayesian-Nonparametric-clustering-model","page":"of Type System","title":"Bayesian Nonparametric clustering model","text":"# Dirichlet Process Mixture Model with truncation\nDPMModel = @of(\n    n_obs = of(Int, 10, 1000; constant=true),      # Number of observations\n    n_features = of(Int, 1, 20; constant=true),    # Feature dimension\n    max_clusters = of(Int, 10, 50; constant=true), # Truncation level for DP\n    \n    # Observed data (n_obs × n_features)\n    data = of(Array, n_obs, n_features),\n    \n    # Cluster assignments (n_obs vector)\n    z = of(Array, n_obs),\n    \n    # Stick-breaking weights (max_clusters - 1 vector)\n    v = of(Array, max_clusters - 1),\n    \n    # Cluster weights derived from stick-breaking (max_clusters vector)\n    weights = of(Array, max_clusters),\n    \n    # Cluster parameters: means (max_clusters × n_features)\n    cluster_means = of(Array, max_clusters, n_features),\n    \n    # Cluster parameters: precisions (max_clusters vector)\n    cluster_precs = of(Array, max_clusters),\n    \n    # Concentration parameter\n    alpha = of(Real, 0.1, 10.0)\n)\n\n# Create instance with specific dimensions\ninstance = DPMModel(; n_obs=100, n_features=2, max_clusters=20)\n# This creates an instance with (all defaulting to zero/appropriate defaults):\n# - data: 100×2 array of observations\n# - z: 100-element vector of cluster assignments\n# - v: 19-element vector of stick-breaking proportions\n# - weights: 20-element vector of cluster weights\n# - cluster_means: 20×2 array of cluster centers\n# - cluster_precs: 20-element vector of cluster precisions\n# - alpha: concentration parameter\n\n@model function dp_mixture(\n    (;data, z, v, weights, cluster_means, cluster_precs, alpha)::DPMModel, \n    n_obs, n_features, max_clusters\n)\n    # Prior on concentration parameter\n    alpha ~ Gamma(1.0, 1.0)\n    \n    # Stick-breaking construction for weights\n    for k in 1:(max_clusters-1)\n        v[k] ~ Beta(1.0, alpha)\n    end\n    \n    # Compute weights from stick-breaking\n    remaining = 1.0\n    for k in 1:max_clusters\n        if k < max_clusters\n            weights[k] = v[k] * remaining\n            remaining *= (1 - v[k])\n        else\n            weights[k] = remaining  # Last weight gets all remaining mass\n        end\n    end\n    \n    # Priors on cluster parameters\n    for k in 1:max_clusters\n        cluster_precs[k] ~ Gamma(1.0, 1.0)\n        for d in 1:n_features\n            cluster_means[k,d] ~ Normal(0.0, 10.0)\n        end\n    end\n    \n    # Data likelihood\n    for i in 1:n_obs\n        # Cluster assignment\n        z[i] ~ Categorical(weights)\n        \n        # Observation given cluster\n        for d in 1:n_features\n            data[i,d] ~ Normal(cluster_means[z[i],d], 1/sqrt(cluster_precs[z[i]]))\n        end\n    end\nend\n\n# Create instance for 50 observations, up to 10 clusters\ndpm = DPMModel(; n_obs=50, n_features=2, max_clusters=10)","category":"section"},{"location":"#JuliaBUGS.jl","page":"Home","title":"JuliaBUGS.jl","text":"JuliaBUGS is a graph-based probabilistic programming framework inspired by the BUGS language.\n\nKey features of JuliaBUGS include:\n\nCompatibility with existing BUGS programs\nExtensibility through user-defined functions and distributions; programmable inference\nSeamless integration with Julia's high-performance numerical and scientific computing libraries\nAutomatic differentiation and sampling using Hamiltonian Monte Carlo\n\nIt's important to note that while BUGS traditionally refers to either the software system, the language, or the inference algorithm, JuliaBUGS is a pure Julia implementation of the BUGS language, not a wrapper for the BUGS system.","category":"section"},{"location":"#Understanding-the-BUGS-Language","page":"Home","title":"Understanding the BUGS Language","text":"The BUGS (Bayesian inference Using Gibbs Sampling) language is designed for specifying directed graphical models in probabilistic programming. Unlike imperative probabilistic programming languages such as Turing.jl or Pyro, BUGS focuses on declarative relationships between nodes in a graph.\n\nThis graph-based approach offers several advantages:\n\nClarity: It provides a clear understanding of dependencies and relationships within complex systems.\nTransparency: Users can explicitly state conditional dependencies between variables, making model structure and assumptions more transparent.\nEase of development and interpretation: The graphical representation aids in both model development and result interpretation.\nEfficient inference: The graph structure facilitates the application of advanced inference algorithms, enabling more efficient computation by leveraging the model's structure.\n\nBy adopting this approach, JuliaBUGS aims to combine the clarity and power of graphical models with the performance and flexibility of the Julia programming language.","category":"section"},{"location":"api/api/#API","page":"General","title":"API","text":"","category":"section"},{"location":"api/api/#Model-Definition-and-Compilation","page":"General","title":"Model Definition and Compilation","text":"","category":"section"},{"location":"api/api/#Type-Specifications","page":"General","title":"Type Specifications","text":"","category":"section"},{"location":"api/api/#JuliaBUGS.Parser.@bugs","page":"General","title":"JuliaBUGS.Parser.@bugs","text":"@bugs(program::Expr)\n@bugs(program::String; replace_period::Bool=true, no_enclosure::Bool=false)\n\nConstructs a Julia Abstract Syntax Tree (AST) representation of a BUGS program. This macro supports two forms of input: a Julia expression or a string containing the BUGS program code. \n\nWhen provided with a string, the macro parses it as a BUGS program, with optional arguments to control parsing behavior.\nWhen given an expression, it performs syntactic checks to ensure compatibility with BUGS syntax.\n\nArguments for String Input\n\nFor the string input variant, the following optional arguments are available:\n\nreplace_period::Bool: When set to true, all periods (.) in the BUGS code are replaced. This is enabled by default.\nno_enclosure::Bool: When true, the parser does not require the BUGS program to be enclosed within model{ ... } brackets. By default, this is set to false.\n\n\n\n\n\n","category":"macro"},{"location":"api/api/#JuliaBUGS.@model","page":"General","title":"JuliaBUGS.@model","text":"@model function_definition\n\nDefine a probabilistic model using JuliaBUGS syntax.\n\nThe @model macro transforms a function definition into a model-generating function. When called, this function returns a compiled BUGSModel object that can be used for inference.\n\nFunction Signature\n\nThe macro creates a function with this pattern:\n\n@model function model_name(\n    (; param1, param2, ...)::OptionalOfType,  # Stochastic parameters (first argument)\n    constant1, constant2, ...                  # Constants and covariates\n)\n    # Model body with probabilistic statements using ~\nend\n\nThis generates a function model_name that, when called with appropriate arguments, returns a BUGSModel instance.\n\nArguments\n\nFirst argument: A named tuple destructuring pattern for stochastic parameters\nMust use the syntax (; name1, name2, ...)\nCan optionally include an of type annotation like (; x, y)::MyOfType\nContains all variables that have probability distributions in the model\nRemaining arguments: Constants, covariates, and structural parameters\nThese are deterministic values that don't have distributions\nExamples: covariate matrices, sample sizes, fixed hyperparameters\n\nModel Body\n\nInside the model body, use the ~ operator to specify probability distributions:\n\ny ~ dnorm(mu, tau)     # y follows a normal distribution\ntheta ~ dgamma(a, b)   # theta follows a gamma distribution\n\nReturns\n\nThe generated function returns a BUGSModel object when called with appropriate arguments.\n\nExamples\n\nSimple Linear Regression\n\n# Define the model-generating function\n@model function regression(\n    (; y, beta, sigma),  # y is observed data, beta and sigma are parameters\n    X, N                 # X is covariate matrix, N is number of observations\n)\n    for i in 1:N\n        mu[i] = X[i, :] ⋅ beta\n        y[i] ~ dnorm(mu[i], sigma)\n    end\n    beta ~ dnorm(0, 0.001)\n    sigma ~ dgamma(0.001, 0.001)\nend\n\n# Call the function to create a model instance\nmodel = regression((; y = observed_data), X_matrix, length(observed_data))\n# `model` is now a BUGSModel object\n\nWith Type Specification\n\n# Define parameter structure\nRegressionParams = @of(\n    y = of(Array, Float64, 100),\n    beta = of(Array, Float64, 3),\n    sigma = of(Real, 0, nothing)\n)\n\n# Define the model-generating function with type annotation\n@model function typed_regression(\n    (; y, beta, sigma)::RegressionParams,\n    X, N\n)\n    # Model body...\nend\n\n# Create a model instance\nmodel = typed_regression((; y = data), X, N)\n\nNotes\n\nThe macro performs compile-time validation of the model structure\nType annotations are validated after model compilation\nOnly of types created with @of are supported for type annotations\nThe first argument must always be a destructuring pattern, not a regular variable\nEach call to the generated function creates a new BUGSModel instance\n\nSee also: @bugs, compile, of, @of\n\n\n\n\n\n","category":"macro"},{"location":"api/api/#JuliaBUGS.compile","page":"General","title":"JuliaBUGS.compile","text":"compile(model_def, data[, initial_params]; adtype=nothing)\n\nCompile a BUGS model. Returns BUGSModel, or BUGSModelWithGradient if adtype is provided.\n\nArguments\n\nmodel_def::Expr: Model definition from @bugs macro\ndata::NamedTuple: Observed data\ninitial_params::NamedTuple: Initial parameter values (optional, defaults to prior samples)\nadtype: AD backend from ADTypes.jl (e.g., AutoReverseDiff(), AutoForwardDiff(), AutoMooncake())\n\nExamples\n\nmodel = compile(model_def, data)\nmodel = compile(model_def, data; adtype=AutoReverseDiff())\n\n\n\n\n\n","category":"function"},{"location":"api/api/#JuliaBUGS.Model.initialize!","page":"General","title":"JuliaBUGS.Model.initialize!","text":"initialize!(model::BUGSModel, initial_params::NamedTuple{<:Any, <:Tuple{Vararg{AllowedValue}}})\n\nInitialize the model with a NamedTuple of initial values, the values are expected to be in the original space.\n\n\n\n\n\ninitialize!(model::BUGSModel, initial_params::AbstractVector)\n\nInitialize the model with a vector of initial values, the values can be in transformed space if model.transformed is set to true.\n\n\n\n\n\n","category":"function"},{"location":"api/api/#JuliaBUGS.of","page":"General","title":"JuliaBUGS.of","text":"of(T, args...; constant::Bool=false)\n\nCreate an OfType specification from various inputs.\n\nMain Methods\n\nArrays\n\nof(Array, dims...)              # Float64 array with given dimensions\nof(Array, T, dims...)           # Array with element type T and given dimensions\n\nReal Numbers\n\nof(Float64)                     # Unbounded Float64\nof(Float64, lower, upper)       # Bounded Float64\nof(Float32)                     # Unbounded Float32\nof(Float32, lower, upper)       # Bounded Float32\nof(Real)                        # Unbounded Real (defaults to Float64)\nof(Real, lower, upper)          # Bounded Real (defaults to Float64)\n\nIntegers\n\nof(Int)                         # Unbounded integer\nof(Int, lower, upper)           # Bounded integer\n\nNamed Tuples\n\nof((;field1=spec1, field2=spec2, ...))  # NamedTuple with typed fields\n\nFrom Values (Type Inference)\n\nof(1.0)                         # Infers of(Float64)\nof([1, 2, 3])                   # Infers of(Array, Int, 3)\nof((a=1, b=2.0))               # Infers OfNamedTuple\n\nArguments\n\nT: Type to create specification for\nargs...: Type-specific arguments (bounds, dimensions, etc.)\nconstant: Mark type as constant/hyperparameter (default: false)\n\nReturns\n\nAn OfType subtype encoding the specification in its type parameters.\n\nExamples\n\n# Basic types\nT1 = of(Float64, 0, 1)          # OfReal{Float64, 0, 1}\nT2 = of(Array, 3, 4)            # OfArray{Float64, 2, (3, 4)}\nT3 = of(Int; constant=true)     # OfConstantWrapper{OfInt{Nothing, Nothing}}\n\n# With @of macro for cleaner syntax\nT4 = @of(\n    n = of(Int; constant=true),\n    data = of(Array, n, 2)      # Symbolic dimension\n)\n\n# Type concretization\nT5 = of(T4; n=10)               # Concrete type with n=10\n\nSee also\n\n@of, OfType\n\n\n\n\n\nof(model::BUGSModel)\n\nExtract the of type specification from a compiled BUGSModel.\n\nThis function introspects the model's evaluation environment to reconstruct the corresponding  of type specification. This is useful for:\n\nModel introspection and debugging\nType validation after compilation\nGeneric code that needs to work with models without knowing their structure\nModel serialization and deserialization\n\nArguments\n\nmodel::BUGSModel: A compiled BUGS model\n\nReturns\n\nAn OfNamedTuple type representing the structure of all variables in the model\n\nExample\n\n# Define and compile a model\n@model function regression((; y, beta, sigma), X, N)\n    # ... model definition ...\nend\n\nmodel = regression((; y = data), X, N)\n\n# Extract the of type from the compiled model\nModelType = of(model)\n# ModelType might be: @of(y = of(Array, Float64, 100), beta = of(Array, Float64, 3), sigma = of(Real, 0, nothing))\n\n# Use the extracted type\nrand(ModelType)  # Generate random values matching the model structure\n\n\n\n\n\nof(::Type{T}, replacements::NamedTuple) where T<:OfType\nof(::Type{T}; kwargs...) where T<:OfType\nof(::Type{T}, pairs::Pair{Symbol}...) where T<:OfType\n\nCreate a concrete type by resolving symbolic dimensions and removing constants.\n\nThis function takes an OfType with symbolic dimensions or constants and creates a new type with some or all symbols resolved to concrete values. Constants that are provided are removed from the resulting type.\n\nArguments\n\nT<:OfType: The type to concretize\nreplacements: Named tuple or keyword arguments mapping symbols to values\n\nReturns\n\nA new OfType with symbols replaced and constants removed.\n\nExamples\n\n# Define type with symbolic dimensions\nT = @of(\n    n = of(Int; constant=true),\n    data = of(Array, n, 2)\n)\n\n# Create concrete type\nConcreteT = of(T; n=10)      # @of(data=of(Array, 10, 2))\n\n# Partial concretization\nT2 = @of(\n    rows = of(Int; constant=true),\n    cols = of(Int; constant=true),\n    matrix = of(Array, rows, cols)\n)\nPartial = of(T2; rows=5)     # @of(cols=of(Int; constant=true), matrix=of(Array, 5, :cols))\n\nSee also\n\nof, @of\n\n\n\n\n\n","category":"function"},{"location":"api/api/#JuliaBUGS.@of","page":"General","title":"JuliaBUGS.@of","text":"@of(field1=spec1, field2=spec2, ...)\n\nCreate an OfNamedTuple type with cleaner syntax for field references.\n\nThe @of macro provides a more intuitive syntax for creating named tuple types where fields can reference each other. Field names used in dimensions or bounds are automatically converted to symbolic references.\n\nSyntax\n\n@of(\n    field_name = of_specification,\n    ...\n)\n\nFeatures\n\nDirect field references without quoting (e.g., n instead of :n)\nSupport for arithmetic expressions in dimensions (e.g., n+1, 2*n)\nAutomatic conversion to appropriate OfNamedTuple type\nFields are processed in order, allowing later fields to reference earlier ones\n\nExamples\n\n# Basic usage with constants and arrays\nT = @of(\n    n = of(Int; constant=true),\n    mu = of(Real),\n    data = of(Array, n, 2)  # 'n' automatically converted to symbolic reference\n)\n\n# With arithmetic expressions\nT = @of(\n    n = of(Int; constant=true),\n    original = of(Array, n, n),\n    padded = of(Array, n+1, n+1),\n    doubled = of(Array, 2*n, n)\n)\n\n# Nested structures\nT = @of(\n    dims = @of(\n        rows = of(Int; constant=true),\n        cols = of(Int; constant=true)\n    ),\n    matrix = of(Array, dims.rows, dims.cols)\n)\n\nSee also\n\nof, OfNamedTuple\n\n\n\n\n\n","category":"macro"},{"location":"api/api/#JuliaBUGS.of-Tuple{JuliaBUGS.Model.BUGSModel}","page":"General","title":"JuliaBUGS.of","text":"of(model::BUGSModel)\n\nExtract the of type specification from a compiled BUGSModel.\n\nThis function introspects the model's evaluation environment to reconstruct the corresponding  of type specification. This is useful for:\n\nModel introspection and debugging\nType validation after compilation\nGeneric code that needs to work with models without knowing their structure\nModel serialization and deserialization\n\nArguments\n\nmodel::BUGSModel: A compiled BUGS model\n\nReturns\n\nAn OfNamedTuple type representing the structure of all variables in the model\n\nExample\n\n# Define and compile a model\n@model function regression((; y, beta, sigma), X, N)\n    # ... model definition ...\nend\n\nmodel = regression((; y = data), X, N)\n\n# Extract the of type from the compiled model\nModelType = of(model)\n# ModelType might be: @of(y = of(Array, Float64, 100), beta = of(Array, Float64, 3), sigma = of(Real, 0, nothing))\n\n# Use the extracted type\nrand(ModelType)  # Generate random values matching the model structure\n\n\n\n\n\n","category":"method"},{"location":"example/#Example:-Logistic-Regression-with-Random-Effects","page":"Getting Started","title":"Example: Logistic Regression with Random Effects","text":"We will use the Seeds for demonstration. This example concerns the proportion of seeds that germinated on each of 21 plates. Here, we transform the data into a NamedTuple:\n\ndata = (\n    r = [10, 23, 23, 26, 17, 5, 53, 55, 32, 46, 10, 8, 10, 8, 23, 0, 3, 22, 15, 32, 3],\n    n = [39, 62, 81, 51, 39, 6, 74, 72, 51, 79, 13, 16, 30, 28, 45, 4, 12, 41, 30, 51, 7],\n    x1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    x2 = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n    N = 21,\n)\n\nwhere r[i] is the number of germinated seeds and n[i] is the total number of the seeds on the i-th plate. Let p_i be the probability of germination on the i-th plate. Then, the model is defined by:\n\nbeginaligned\nb_i sim textNormal(0 tau) \ntextlogit(p_i) = alpha_0 + alpha_1 x_1 i + alpha_2 x_2i + alpha_12 x_1i x_2i + b_i \nr_i sim textBinomial(p_i n_i)\nendaligned\n\nwhere x_1i and x_2i are the seed type and root extract of the i-th plate.   The original BUGS program for the model is:\n\nmodel\n{\n    for( i in 1 : N ) {\n        r[i] ~ dbin(p[i],n[i])\n        b[i] ~ dnorm(0.0,tau)\n        logit(p[i]) <- alpha0 + alpha1 * x1[i] + alpha2 * x2[i] +\n        alpha12 * x1[i] * x2[i] + b[i]\n    }\n    alpha0 ~ dnorm(0.0, 1.0E-6)\n    alpha1 ~ dnorm(0.0, 1.0E-6)\n    alpha2 ~ dnorm(0.0, 1.0E-6)\n    alpha12 ~ dnorm(0.0, 1.0E-6)\n    tau ~ dgamma(0.001, 0.001)\n    sigma <- 1 / sqrt(tau)\n}","category":"section"},{"location":"example/#Modeling-Language","page":"Getting Started","title":"Modeling Language","text":"","category":"section"},{"location":"example/#Writing-a-Model-in-BUGS","page":"Getting Started","title":"Writing a Model in BUGS","text":"Language References:\n\nMultiBUGS\nOpenBUGS\n\nImplementations in C++ and R:\n\nJAGS and its user manual\nNimble\n\nLanguage Syntax:\n\nBNF","category":"section"},{"location":"example/#Writing-a-Model-in-Julia","page":"Getting Started","title":"Writing a Model in Julia","text":"We provide a macro which allows users to write down model definitions using Julia:\n\nmodel_def = @bugs begin\n    for i in 1:N\n        r[i] ~ dbin(p[i], n[i])\n        b[i] ~ dnorm(0.0, tau)\n        p[i] = logistic(alpha0 + alpha1 * x1[i] + alpha2 * x2[i] + alpha12 * x1[i] * x2[i] + b[i])\n    end\n    alpha0 ~ dnorm(0.0, 1.0E-6)\n    alpha1 ~ dnorm(0.0, 1.0E-6)\n    alpha2 ~ dnorm(0.0, 1.0E-6)\n    alpha12 ~ dnorm(0.0, 1.0E-6)\n    tau ~ dgamma(0.001, 0.001)\n    sigma = 1 / sqrt(tau)\nend\n\nBUGS syntax carries over almost one-to-one to Julia, with minor exceptions. Modifications required are minor: curly braces are replaced with begin ... end blocks, and for loops do not require parentheses. In addition, Julia uses f(x) = ... as a shorthand for function definition, so BUGS' link function syntax is disallowed. Instead, user can call the inverse function of the link functions on the RHS expressions.","category":"section"},{"location":"example/#Support-for-Legacy-BUGS-Programs","page":"Getting Started","title":"Support for Legacy BUGS Programs","text":"The @bugs macro also works with original (R-like) BUGS syntax:\n\nmodel_def = @bugs(\"\"\"\nmodel{\n    for( i in 1 : N ) {\n        r[i] ~ dbin(p[i],n[i])\n        b[i] ~ dnorm(0.0,tau)\n        logit(p[i]) <- alpha0 + alpha1 * x1[i] + alpha2 * x2[i] +\n        alpha12 * x1[i] * x2[i] + b[i]\n    }\n    alpha0 ~ dnorm(0.0,1.0E-6)\n    alpha1 ~ dnorm(0.0,1.0E-6)\n    alpha2 ~ dnorm(0.0,1.0E-6)\n    alpha12 ~ dnorm(0.0,1.0E-6)\n    tau ~ dgamma(0.001,0.001)\n    sigma <- 1 / sqrt(tau)\n}\n\"\"\", true, true)\n\nBy default, @bugs will translate R-style variable names like a.b.c to a_b_c, user can pass false as the second argument to disable this. User can also pass true as the third argument if model { } enclosure is not present in the BUGS program. We still encourage users to write new programs using the Julia-native syntax, because of better debuggability and perks like syntax highlighting.","category":"section"},{"location":"example/#Basic-Workflow","page":"Getting Started","title":"Basic Workflow","text":"","category":"section"},{"location":"example/#Compilation","page":"Getting Started","title":"Compilation","text":"Model definition and data are the two necessary inputs for compilation, with optional initializations. The compile function creates a BUGSModel that implements the LogDensityProblems.jl interface.\n\ncompile(model_def::Expr, data::NamedTuple)\n\nAnd with initializations:\n\ncompile(model_def::Expr, data::NamedTuple, initializations::NamedTuple)\n\nUsing the model definition and data we defined earlier, we can compile the model:\n\nmodel = compile(model_def, data)\nshow(model) # hide\n\nParameter values will be sampled from the prior distributions in the original space.\n\nWe can provide initializations:\n\ninitializations = (alpha = 1, beta = 1)\n\ncompile(model_def, data, initializations)\n\nWe can also initialize parameters after compilation:\n\ninitialize!(model, initializations)\n\ninitialize! also accepts a flat vector. In this case, the vector should have the same length as the number of parameters, but values can be in transformed space:\n\ninitialize!(model, rand(26))","category":"section"},{"location":"example/#Inference","page":"Getting Started","title":"Inference","text":"For gradient-based inference, compile your model with an AD backend using the adtype parameter (see Automatic Differentiation for details). We use AdvancedHMC.jl:\n\n# Compile with gradient support\nmodel = compile(model_def, data; adtype=AutoReverseDiff(compile=true))\n\nn_samples, n_adapts = 2000, 1000\n\nD = LogDensityProblems.dimension(model); initial_θ = rand(D)\n\nsamples_and_stats = AbstractMCMC.sample(\n                        model,\n                        NUTS(0.8),\n                        n_samples;\n                        chain_type = Chains,\n                        n_adapts = n_adapts,\n                        init_params = initial_θ,\n                        discard_initial = n_adapts,\n                        progress = false\n                    )\ndescribe(samples_and_stats)\n\nThis is consistent with the result in the OpenBUGS seeds example.","category":"section"},{"location":"example/#Next-Steps","page":"Getting Started","title":"Next Steps","text":"Automatic Differentiation - AD backends and configuration\nEvaluation Modes - Different log density computation modes\nAuto-Marginalization - Gradient-based inference with discrete variables\nParallel Sampling - Multi-threaded and distributed sampling","category":"section"},{"location":"example/#More-Examples","page":"Getting Started","title":"More Examples","text":"We have transcribed all the examples from the first volume of the BUGS Examples (original and transcribed). All programs and data are included, and can be compiled using the steps described in the tutorial above.","category":"section"}]
}
